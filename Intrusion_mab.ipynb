{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#constant"
      ],
      "metadata": {
        "id": "N0uMT0MalczV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "e510eMhalX_Y"
      },
      "outputs": [],
      "source": [
        "DURATION = 'duration'\n",
        "PROTOCOL_TYPE = 'protocol_type'\n",
        "SERVICE = 'service'\n",
        "FLAG = 'flag'\n",
        "SRC_BYTES = 'src_bytes'\n",
        "DST_BYTES = 'dst_bytes'\n",
        "LAND = 'land'\n",
        "WRONG_FRAGMENT = 'wrong_fragment'\n",
        "URGENT = 'urgent'\n",
        "HOT = 'hot'\n",
        "NUM_FAILED_LOGINS = 'num_failed_logins'\n",
        "LOGGED_IN = 'logged_in'\n",
        "NUM_COMPROMISED = 'num_compromised'\n",
        "ROOT_SHELL = 'root_shell'\n",
        "SU_ATTEMPTED = 'su_attempted'\n",
        "NUM_ROOT = 'num_root'\n",
        "NUM_FILE_CREATIONS = 'num_file_creations'\n",
        "NUM_SHELLS = 'num_shells'\n",
        "NUM_ACCESS_FILES = 'num_access_files'\n",
        "NUM_OUTBOUND_CMDS = 'num_outbound_cmds'\n",
        "IS_HOST_LOGIN = 'is_host_login'\n",
        "IS_GUEST_LOGIN = 'is_guest_login'\n",
        "COUNT = 'count'\n",
        "SRV_COUNT = 'srv_count'\n",
        "SERROR_RATE = 'serror_rate'\n",
        "SRV_SERROR_RATE = 'srv_serror_rate'\n",
        "RERROR_RATE = 'rerror_rate'\n",
        "SRV_RERROR_RATE = 'srv_rerror_rate'\n",
        "SAME_SRV_RATE = 'same_srv_rate'\n",
        "DIFF_SRV_RATE = 'diff_srv_rate'\n",
        "SRV_DIFF_HOST_RATE = 'srv_diff_host_rate'\n",
        "DST_HOST_COUNT = 'dst_host_count'\n",
        "DST_HOST_SRV_COUNT = 'dst_host_srv_count'\n",
        "DST_HOST_SAME_SRV_RATE = 'dst_host_same_srv_rate'\n",
        "DST_HOST_DIFF_SRV_RATE = 'dst_host_diff_srv_rate'\n",
        "DST_HOST_SAME_SRC_PORT_RATE = 'dst_host_same_src_port_rate'\n",
        "DST_HOST_SRV_DIFF_HOST_RATE = 'dst_host_srv_diff_host_rate'\n",
        "DST_HOST_SERROR_RATE = 'dst_host_serror_rate'\n",
        "DST_HOST_SRV_SERROR_RATE = 'dst_host_srv_serror_rate'\n",
        "DST_HOST_RERROR_RATE = 'dst_host_rerror_rate'\n",
        "DST_HOST_SRV_RERROR_RATE = 'dst_host_srv_rerror_rate'\n",
        "CLASS = 'class'\n",
        "\n",
        "VAL_UNKNOWN=-1\n",
        "\n",
        "NUMERICAL_FEATURES=[DURATION, SRC_BYTES, DST_BYTES, WRONG_FRAGMENT,\n",
        "                    URGENT, HOT, NUM_FAILED_LOGINS, NUM_COMPROMISED, SU_ATTEMPTED, NUM_ROOT,\n",
        "                    NUM_FILE_CREATIONS, NUM_SHELLS,\n",
        "                    NUM_ACCESS_FILES, NUM_OUTBOUND_CMDS,\n",
        "                    COUNT, SRV_COUNT, SERROR_RATE, SRV_SERROR_RATE, RERROR_RATE,\n",
        "                    SRV_RERROR_RATE, SAME_SRV_RATE, DIFF_SRV_RATE, SRV_DIFF_HOST_RATE,\n",
        "                    DST_HOST_COUNT, DST_HOST_SRV_COUNT, DST_HOST_SAME_SRV_RATE,\n",
        "                    DST_HOST_DIFF_SRV_RATE, DST_HOST_SAME_SRC_PORT_RATE,\n",
        "                    DST_HOST_SRV_DIFF_HOST_RATE, DST_HOST_SERROR_RATE,\n",
        "                    DST_HOST_SRV_SERROR_RATE, DST_HOST_RERROR_RATE, DST_HOST_SRV_RERROR_RATE]\n",
        "\n",
        "BINARY_FEATURES =[LAND, LOGGED_IN,ROOT_SHELL, IS_HOST_LOGIN, IS_GUEST_LOGIN]\n",
        "\n",
        "INCORRECT_PRED_REWARD = -1\n",
        "CORRECT_PRED_REWARD = 1\n",
        "\n",
        "CORRECT_LABEL = 1\n",
        "INCORRECT_LABEL =0\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#feature"
      ],
      "metadata": {
        "id": "dBVc9BYyminN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import enum\n",
        "# from constant import *\n",
        "\n",
        "class protocol_type(enum.Enum):\n",
        "    unknown = VAL_UNKNOWN\n",
        "    tcp = 1\n",
        "    udp = 2\n",
        "    icmp =3\n",
        "\n",
        "\n",
        "class Service(enum.Enum):\n",
        "    unknown = VAL_UNKNOWN\n",
        "    aol = 1\n",
        "    auth = 2\n",
        "    bgp = 3\n",
        "    courier = 4\n",
        "    csnet_ns = 5\n",
        "    ctf = 6\n",
        "    daytime = 7\n",
        "    discard = 8\n",
        "    domain = 9\n",
        "    domain_u = 10\n",
        "    echo = 11\n",
        "    eco_i = 12\n",
        "    ecr_i = 13\n",
        "    efs = 14\n",
        "    exec = 15\n",
        "    finger = 16\n",
        "    ftp = 17\n",
        "    ftp_data = 18\n",
        "    gopher = 19\n",
        "    harvest = 20\n",
        "    hostnames = 21\n",
        "    http = 22\n",
        "    http_2784 = 23\n",
        "    http_443 = 24\n",
        "    http_8001 = 25\n",
        "    imap4 = 26\n",
        "    IRC = 27\n",
        "    iso_tsap = 28\n",
        "    klogin = 29\n",
        "    kshell = 30\n",
        "    ldap = 31\n",
        "    link = 32\n",
        "    login = 33\n",
        "    mtp = 34\n",
        "    name = 35\n",
        "    netbios_dgm = 36\n",
        "    netbios_ns = 37\n",
        "    netbios_ssn = 38\n",
        "    netstat = 39\n",
        "    nnsp = 40\n",
        "    nntp = 41\n",
        "    ntp_u = 42\n",
        "    other = 43\n",
        "    pm_dump = 44\n",
        "    pop_2 = 45\n",
        "    pop_3 = 46\n",
        "    printer = 47\n",
        "    private = 48\n",
        "    red_i = 49\n",
        "    remote_job = 50\n",
        "    rje = 51\n",
        "    shell = 52\n",
        "    smtp = 53\n",
        "    sql_net = 54\n",
        "    ssh = 55\n",
        "    sunrpc = 56\n",
        "    supdup = 57\n",
        "    systat = 58\n",
        "    telnet = 59\n",
        "    tftp_u = 60\n",
        "    tim_i = 61\n",
        "    time = 62\n",
        "    urh_i = 63\n",
        "    urp_i = 64\n",
        "    uucp = 65\n",
        "    uucp_path = 66\n",
        "    vmnet = 67\n",
        "    whois = 68\n",
        "    X11 = 69\n",
        "    Z39_50 = 70\n",
        "\n",
        "\n",
        "class Flag(enum.Enum):\n",
        "    unknown = VAL_UNKNOWN\n",
        "    OTH = 1\n",
        "    REJ = 2\n",
        "    RSTO = 3\n",
        "    RSTOS0 = 4\n",
        "    RSTR = 5\n",
        "    S0 = 6\n",
        "    S1 = 7\n",
        "    S2 = 8\n",
        "    S3 = 9\n",
        "    SF = 10\n",
        "    SH = 11\n",
        "\n",
        "class BinaryFeatures(enum.Enum):\n",
        "    unknown = VAL_UNKNOWN\n",
        "    true = 1\n",
        "    false = 0"
      ],
      "metadata": {
        "id": "xtv6XmMOmkT4"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#util\n"
      ],
      "metadata": {
        "id": "7hHps7Jom0BP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import csv\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "import matplotlib.pyplot as plt\n",
        "# from constant import *\n",
        "\n",
        "\n",
        "def undefined(s):\n",
        "    if isinstance(s, str):\n",
        "        s = s.strip()\n",
        "    return s is None or s == \"NA\" or s == \"\"\n",
        "\n",
        "\n",
        "def clean_value(s):\n",
        "    result = s\n",
        "    if undefined(s):\n",
        "        result = None\n",
        "    elif isinstance(s, str):\n",
        "        result = s.strip().lower()\n",
        "    return result\n",
        "\n",
        "\n",
        "def get_float(s):\n",
        "    value = clean_value(s)\n",
        "\n",
        "    if value is not None:\n",
        "        try:\n",
        "            value = float(s)\n",
        "        except ValueError:\n",
        "            value = VAL_UNKNOWN\n",
        "    else:\n",
        "        value = VAL_UNKNOWN\n",
        "\n",
        "    return value\n",
        "\n",
        "\n",
        "def get_int(s):\n",
        "    value = clean_value(s)\n",
        "    if value is not None:\n",
        "        try:\n",
        "            value = int(s)\n",
        "        except ValueError:\n",
        "            value = VAL_UNKNOWN\n",
        "    else:\n",
        "        value = VAL_UNKNOWN\n",
        "\n",
        "    return value\n",
        "\n",
        "\n",
        "def export_stats_list(stats_list, filename):\n",
        "    \"\"\"\n",
        "    Export a stats list to a file\n",
        "\n",
        "    Args:\n",
        "        stats_list: (list) of stats in float / int\n",
        "        filename: (string) directory\n",
        "    \"\"\"\n",
        "    with open(filename, 'w') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerows(stats_list)\n",
        "\n",
        "\n",
        "def export_plot(ys, ylabel, title, filename):\n",
        "    \"\"\"\n",
        "    Export a plot in filename\n",
        "\n",
        "    Args:\n",
        "        ys: (list) of float / int to plot\n",
        "        filename: (string) directory\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    plt.plot(range(len(ys)), ys)\n",
        "    plt.xlabel(\"Network Count\")\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title)\n",
        "    plt.savefig(filename)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "#\n",
        "# https://math.stackexchange.com/questions/102978/incremental-computation-of-standard-deviation\n",
        "#\n",
        "def variance_update(prev_s2, n, prev_mu, x_n):\n",
        "    s2 = ((n - 2)/(n - 1))*prev_s2  if n > 2 else 0\n",
        "    s2 += (1/n) * pow((x_n - prev_mu), 2)\n",
        "    return s2\n",
        "\n",
        "\n",
        "def mean_update(prev_mu, n, x_n):\n",
        "    return (1/n)*(x_n + (n - 1)*prev_mu)\n",
        "\n",
        "\n",
        "def print_flush(s, end='\\n'):\n",
        "    print(s, end=end)\n",
        "    sys.stdout.flush()\n"
      ],
      "metadata": {
        "id": "TaXIi67Wm3sI"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#preprocessing"
      ],
      "metadata": {
        "id": "fytQ_VmMnERl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "# from feature import *\n",
        "# from .util import *\n",
        "\n",
        "\n",
        "def feature_scaling(min, max, value):\n",
        "    \"\"\"\n",
        "    Perform Min-Max Scaling on the given value based on the provided min and max range\n",
        "    :param min: minimum value\n",
        "    :param max: maximum value\n",
        "    :param value: actual value\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    scaled = VAL_UNKNOWN\n",
        "    if value is not None and min is not None and max is not None and max > min:\n",
        "        scaled = (value - min) / (max - min)\n",
        "    return scaled\n",
        "\n",
        "\n",
        "def get_one_hot(enum_value):\n",
        "    \"\"\"\n",
        "    Convert enum value into one hot vector\n",
        "\n",
        "    :param enum_value: input categorical enum value\n",
        "    :return: one hot vector for the given enum value\n",
        "    \"\"\"\n",
        "    enum_type = type(enum_value)\n",
        "    results = [0] * len(enum_type)\n",
        "    enum_list = list(enum_type)\n",
        "    if enum_value in enum_list:\n",
        "        results[enum_list.index(enum_value)] = 1\n",
        "    return results\n",
        "\n",
        "\n",
        "def get_one_hot_from_list(enum_value_list):\n",
        "    results = []\n",
        "    if enum_value_list is not None and len(enum_value_list) > 0:\n",
        "        enum_type = type(enum_value_list[0])\n",
        "        results = [0] * len(enum_type)\n",
        "        enum_list = list(enum_type)\n",
        "        for enum_value in enum_value_list:\n",
        "            if enum_value in enum_list:\n",
        "                results[enum_list.index(enum_value)] = 1\n",
        "    return results\n",
        "\n",
        "\n",
        "def parse_label(d):\n",
        "    \"\"\"\n",
        "    convert dose (string) to na/low/med/high integers\n",
        "        0: < 21 mg/week  (LOW)\n",
        "        1: <= 49 mg/week  (MEDIUM)\n",
        "        2: else mg/week  (HIGH)\n",
        "    \"\"\"\n",
        "    # result = VAL_UNKNOWN\n",
        "\n",
        "    s = clean_value(d)\n",
        "    # print(s)\n",
        "    result = VAL_UNKNOWN\n",
        "    if s != None:\n",
        "        if s =='normal':\n",
        "            result = CORRECT_LABEL\n",
        "        elif s =='anomaly':\n",
        "            # print('ksfkjsjflksmfsk')\n",
        "            result = INCORRECT_LABEL\n",
        "            # print('result' , result)\n",
        "    return result\n",
        "\n",
        "\n",
        "def parse_protocol(s):\n",
        "    \"\"\"\n",
        "    Parse 'Gender' column in the csv and return corresponding Gender enum\n",
        "\n",
        "    :param s: input string\n",
        "    :return: Gender enum\n",
        "    \"\"\"\n",
        "    pt = protocol_type.unknown\n",
        "    s = clean_value(s)\n",
        "    if s == \"tcp\":\n",
        "        pt = protocol_type.tcp\n",
        "    elif s == \"udp\":\n",
        "        pt = protocol_type.udp\n",
        "\n",
        "    elif s == \"icmp\":\n",
        "        pt = protocol_type.icmp\n",
        "\n",
        "    return pt\n",
        "\n",
        "def parse_flag(s):\n",
        "    \"\"\"\n",
        "    Parse 'Race' column in the csv and return corresponding Race enum\n",
        "\n",
        "    :param s: input string\n",
        "    :return: Race enum\n",
        "\n",
        "    class Flag(enum.Enum):\n",
        "    unknown = VAL_UNKNOWN\n",
        "    OTH = 1\n",
        "    REJ = 2\n",
        "    RSTO = 3\n",
        "    RSTOS0 = 4\n",
        "    RSTR = 5\n",
        "    S0 = 6\n",
        "    S1 = 7\n",
        "    S2 = 8\n",
        "    S3 = 9\n",
        "    SF = 10\n",
        "    SH = 11\n",
        "    \"\"\"\n",
        "    flag = Flag.unknown\n",
        "    s = clean_value(s)\n",
        "    if s == \"oth\":\n",
        "        flag = Flag.OTH\n",
        "    elif s == \"rej\":\n",
        "        flag= Flag.REJ\n",
        "    elif s == \"rsto\":\n",
        "        flag= Flag.RSTO\n",
        "    elif s == \"rstos0\":\n",
        "        flag= Flag.RSTOS0\n",
        "    elif s == \"rstr\":\n",
        "        flag= Flag.RSTR\n",
        "    elif s == \"s0\":\n",
        "        flag= Flag.S0\n",
        "    elif s == \"s1\":\n",
        "        flag= Flag.S1\n",
        "    elif s == \"s2\":\n",
        "        flag= Flag.S2\n",
        "    elif s == \"s3\":\n",
        "        flag= Flag.S3\n",
        "    elif s == \"sf\":\n",
        "        flag= Flag.SF\n",
        "    elif s == \"sh\":\n",
        "        flag= Flag.SH\n",
        "    return flag\n",
        "\n",
        "\n",
        "def parse_service(s):\n",
        "    \"\"\"\n",
        "    Parse 'Age' column in the csv and return corresponding AgeGroup enum\n",
        "\n",
        "    :param s: input string\n",
        "    :return: AgeGroup enum\n",
        "    \"\"\"\n",
        "    serv = Service.unknown\n",
        "    s = clean_value(s)\n",
        "\n",
        "    if s == \"aol\":\n",
        "        serv = Service.aol\n",
        "    elif s == \"auth\":\n",
        "        serv = Service.auth\n",
        "    elif s == \"bgp\":\n",
        "        serv = Service.bgp\n",
        "    elif s == \"courier\":\n",
        "        serv = Service.courier\n",
        "    elif s == \"csnet_ns\":\n",
        "        serv = Service.csnet_ns\n",
        "    elif s == \"ctf\":\n",
        "        serv = Service.ctf\n",
        "    elif s == \"daytime\":\n",
        "        serv = Service.daytime\n",
        "    elif s == \"discard\":\n",
        "        serv = Service.discard\n",
        "    elif s == \"domain\":\n",
        "        serv = Service.domain\n",
        "    elif s == \"domain_u\":\n",
        "        serv = Service.domain_u\n",
        "    elif s == \"echo\":\n",
        "        serv = Service.echo\n",
        "    elif s == \"eco_i\":\n",
        "        serv = Service.eco_i\n",
        "    elif s == \"ecr_i\":\n",
        "        serv = Service.ecr_i\n",
        "    elif s == \"efs\":\n",
        "        serv = Service.efs\n",
        "    elif s == \"exec\":\n",
        "        serv = Service.exec\n",
        "    elif s == \"finger\":\n",
        "        serv = Service.finger\n",
        "    elif s == \"ftp\":\n",
        "        serv = Service.ftp\n",
        "    elif s == \"ftp_data\":\n",
        "        serv = Service.ftp_data\n",
        "    elif s == \"gopher\":\n",
        "        serv = Service.gopher\n",
        "    elif s == \"harvest\":\n",
        "        serv = Service.harvest\n",
        "    elif s == \"hostnames\":\n",
        "        serv = Service.hostnames\n",
        "    elif s == \"http\":\n",
        "        serv = Service.http\n",
        "    elif s == \"http_2784\":\n",
        "        serv = Service.http_2784\n",
        "    elif s == \"http_443\":\n",
        "        serv = Service.http_443\n",
        "    elif s == \"http_8001\":\n",
        "        serv = Service.http_8001\n",
        "    elif s == \"imap4\":\n",
        "        serv = Service.imap4\n",
        "    elif s == \"irc\":\n",
        "        serv = Service.IRC\n",
        "    elif s == \"iso_tsap\":\n",
        "        serv = Service.iso_tsap\n",
        "    elif s == \"klogin\":\n",
        "        serv = Service.klogin\n",
        "    elif s == \"kshell\":\n",
        "        serv = Service.kshell\n",
        "    elif s == \"ldap\":\n",
        "        serv = Service.ldap\n",
        "    elif s == \"link\":\n",
        "        serv = Service.link\n",
        "    elif s == \"login\":\n",
        "        serv = Service.login\n",
        "    elif s == \"mtp\":\n",
        "        serv = Service.mtp\n",
        "    elif s == \"name\":\n",
        "        serv = Service.name\n",
        "    elif s == \"netbios_dgm\":\n",
        "        serv = Service.netbios_dgm\n",
        "    elif s == \"netbios_ns\":\n",
        "        serv = Service.netbios_ns\n",
        "    elif s == \"netbios_ssn\":\n",
        "        serv = Service.netbios_ssn\n",
        "    elif s == \"netstat\":\n",
        "        serv = Service.netstat\n",
        "    elif s == \"nnsp\":\n",
        "        serv = Service.nnsp\n",
        "    elif s == \"nntp\":\n",
        "        serv = Service.nntp\n",
        "    elif s == \"ntp_u\":\n",
        "        serv = Service.ntp_u\n",
        "    elif s == \"other\":\n",
        "        serv = Service.other\n",
        "    elif s == \"pm_dump\":\n",
        "        serv = Service.pm_dump\n",
        "    elif s == \"pop_2\":\n",
        "        serv = Service.pop_2\n",
        "    elif s == \"pop_3\":\n",
        "        serv = Service.pop_3\n",
        "    elif s == \"printer\":\n",
        "        serv = Service.printer\n",
        "    elif s == \"private\":\n",
        "        serv = Service.private\n",
        "    elif s == \"red_i\":\n",
        "        serv = Service.red_i\n",
        "    elif s == \"remote_job\":\n",
        "        serv = Service.remote_job\n",
        "    elif s == \"rje\":\n",
        "        serv = Service.rje\n",
        "    elif s == \"shell\":\n",
        "        serv = Service.shell\n",
        "    elif s == \"smtp\":\n",
        "        serv = Service.smtp\n",
        "    elif s == \"sql_net\":\n",
        "        serv = Service.sql_net\n",
        "    elif s == \"ssh\":\n",
        "        serv = Service.ssh\n",
        "    elif s == \"sunrpc\":\n",
        "        serv = Service.sunrpc\n",
        "    elif s == \"supdup\":\n",
        "        serv = Service.supdup\n",
        "    elif s == \"systat\":\n",
        "        serv = Service.systat\n",
        "    elif s == \"telnet\":\n",
        "        serv = Service.telnet\n",
        "    elif s == \"tftp_u\":\n",
        "        serv = Service.tftp_u\n",
        "    elif s == \"tim_i\":\n",
        "        serv = Service.tim_i\n",
        "    elif s == \"time\":\n",
        "        serv = Service.time\n",
        "    elif s == \"urh_i\":\n",
        "        serv = Service.urh_i\n",
        "    elif s == \"urp_i\":\n",
        "        serv = Service.urp_i\n",
        "    elif s == \"uucp\":\n",
        "        serv = Service.uucp\n",
        "    elif s == \"uucp_path\":\n",
        "        serv = Service.uucp_path\n",
        "    elif s == \"vmnet\":\n",
        "        serv = Service.vmnet\n",
        "    elif s == \"whois\":\n",
        "        serv = Service.whois\n",
        "    elif s == \"x11\":\n",
        "        serv = Service.X11\n",
        "    elif s == \"z39_50\":\n",
        "        serv = Service.Z39_50\n",
        "\n",
        "    return serv\n",
        "\n",
        "\n",
        "def parse_binary_feature(d):\n",
        "    result = get_int(d)\n",
        "    return None if result is None else BinaryFeatures(result)\n",
        "\n"
      ],
      "metadata": {
        "id": "lKgGqjHgnF8m"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Network"
      ],
      "metadata": {
        "id": "I94venNZnkc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from feature import *\n",
        "# from .preprocess import *\n",
        "# from .util import *\n",
        "\n",
        "class Network:\n",
        "    \"\"\"\n",
        "    will rename to network_info\n",
        "    \"\"\"\n",
        "    def __init__(self, record):\n",
        "        self.properties = dict()\n",
        "        self.properties[CLASS] = parse_label(record[CLASS])\n",
        "        self.properties[PROTOCOL_TYPE] = parse_protocol(record[PROTOCOL_TYPE])\n",
        "        self.properties[SERVICE]=parse_service(record[SERVICE])\n",
        "        self.properties[DURATION]=get_int(record[DURATION])\n",
        "        self.properties[FLAG] = parse_flag(record[FLAG])\n",
        "        self.properties[SRC_BYTES] = get_int(record[SRC_BYTES])\n",
        "        self.properties[DST_BYTES] = get_int(record[DST_BYTES])\n",
        "        self.properties[WRONG_FRAGMENT] = get_int(record[WRONG_FRAGMENT])\n",
        "        self.properties[URGENT] = get_int(record[URGENT])\n",
        "        self.properties[HOT] = get_int(record[HOT])\n",
        "        self.properties[NUM_FAILED_LOGINS] = get_int(record[NUM_FAILED_LOGINS])\n",
        "        self.properties[NUM_COMPROMISED] = get_int(record[NUM_COMPROMISED])\n",
        "        self.properties[SU_ATTEMPTED] = get_int(record[SU_ATTEMPTED])\n",
        "        self.properties[NUM_ROOT] = get_int(record[NUM_ROOT])\n",
        "        self.properties[NUM_FILE_CREATIONS] =get_int(record[NUM_FILE_CREATIONS])\n",
        "        self.properties[NUM_SHELLS] = get_int(record[NUM_SHELLS])\n",
        "        self.properties[NUM_ACCESS_FILES] = get_int(record[NUM_ACCESS_FILES])\n",
        "        self.properties[NUM_OUTBOUND_CMDS] = get_int(record[NUM_OUTBOUND_CMDS])\n",
        "        self.properties[COUNT] = get_int(record[COUNT])\n",
        "        self.properties[SRV_COUNT] = get_int(record[SRV_COUNT])\n",
        "        self.properties[SERROR_RATE] = get_float(record[SERROR_RATE])\n",
        "        self.properties[SRV_SERROR_RATE] = get_float(record[SRV_SERROR_RATE])\n",
        "        self.properties[RERROR_RATE] = get_float(record[RERROR_RATE])\n",
        "        self.properties[SRV_RERROR_RATE] =get_float(record[SRV_RERROR_RATE])\n",
        "        self.properties[SAME_SRV_RATE] = get_float(record[SAME_SRV_RATE])\n",
        "        self.properties[DIFF_SRV_RATE] = get_float(record[DIFF_SRV_RATE])\n",
        "        self.properties[SRV_DIFF_HOST_RATE] = get_float(record[SRV_DIFF_HOST_RATE])\n",
        "        self.properties[DST_HOST_COUNT] = get_int(record[DST_HOST_COUNT])\n",
        "        self.properties[DST_HOST_SRV_COUNT] = get_int(record[DST_HOST_SRV_COUNT])\n",
        "        self.properties[DST_HOST_SAME_SRV_RATE] = get_float(record[DST_HOST_SAME_SRV_RATE])\n",
        "        self.properties[DST_HOST_DIFF_SRV_RATE] = get_float(record[DST_HOST_DIFF_SRV_RATE])\n",
        "        self.properties[DST_HOST_SAME_SRC_PORT_RATE] =get_float(record[DST_HOST_SAME_SRC_PORT_RATE])\n",
        "        self.properties[DST_HOST_SRV_DIFF_HOST_RATE] = get_float(record[DST_HOST_SRV_DIFF_HOST_RATE])\n",
        "        self.properties[DST_HOST_SERROR_RATE] = get_float(record[DST_HOST_SERROR_RATE])\n",
        "        self.properties[DST_HOST_SRV_SERROR_RATE] = get_float(record[DST_HOST_SRV_SERROR_RATE])\n",
        "        self.properties[DST_HOST_RERROR_RATE] = get_float(record[DST_HOST_RERROR_RATE])\n",
        "        self.properties[DST_HOST_SRV_RERROR_RATE]= get_float(record[DST_HOST_SRV_RERROR_RATE])\n",
        "        for p in BINARY_FEATURES:\n",
        "            self.properties[p] = parse_binary_feature(record[p])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dcgxhc9gnmXD"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Recommender"
      ],
      "metadata": {
        "id": "6EiYFbkjoG9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import numpy as np\n",
        "# from util import *\n",
        "# from constant import *\n",
        "\n",
        "class Recommender(object):\n",
        "    \"\"\"\n",
        "    Abstract Class for implementing a Dose Recommendation Algorithm\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        \"\"\"\n",
        "        Initialize Recommender Class\n",
        "\n",
        "        Args:\n",
        "                config: class with hyperparameters\n",
        "                logger: logger instance from the logging module\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "\n",
        "    def get_reward(self, action, label):\n",
        "        return CORRECT_PRED_REWARD if action == label else INCORRECT_PRED_REWARD\n",
        "\n",
        "    def get_features(self, network):\n",
        "        \"\"\"\n",
        "        Algorithm-specific feature processing\n",
        "\n",
        "        :param network: network data\n",
        "        :return: feature vector for the given network\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reset params.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def update(self, arm, context_feature, reward):\n",
        "        \"\"\"Observe the reward.\n",
        "\n",
        "        Observe the reward for a past action. Update parameters accordingly.\n",
        "\n",
        "        Args:\n",
        "            arm: the previous arm recommended by the bandit.\n",
        "            context_feature: the feature used to compute the previous recommend arm.\n",
        "            reward: the reward corresponding to the previous action.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def recommend(self, network, eval_results, iter, network_idx):\n",
        "        \"\"\"\n",
        "        Recommend an action.\n",
        "\n",
        "        returns:\n",
        "            action: An integer representing the selected action.\n",
        "            payoff: A float representing the estimated payoff of the selected action.\n",
        "            conf_interval: A float representing the confidence interval for the estimated payoff\n",
        "                            of the selected action.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def run(self, networks, indices, eval_results, iter, is_training=False):\n",
        "        \"\"\"\n",
        "        Run the model with the provided network data set.\n",
        "        When training mode is set to True, the model internal weights are updated.\n",
        "        Otherwise, run the model in testing mode with no updates to the weights.\n",
        "\n",
        "        :param networks: complete network data set\n",
        "        :param indices: indicies into the network data set for data points\n",
        "        :param is_training: whether to run the model in training mode (which updates weights)\n",
        "        :return: lists of regrets and mistakes\n",
        "        \"\"\"\n",
        "        regrets, mistakes = [], []\n",
        "        actions, payoffs, conf_intervals = [], [], []\n",
        "        risks = np.zeros((2, 2), dtype=int)  # keep track of decisions made\n",
        "\n",
        "        for i in range(len(indices)):\n",
        "            index = indices[i]\n",
        "            network = networks[index]\n",
        "            features = self.get_features(network)\n",
        "            # skip insufficient records\n",
        "            if features is None:\n",
        "                continue\n",
        "            # ground truth\n",
        "            label = network.properties[CLASS]\n",
        "\n",
        "            action, payoff, conf_interval = self.recommend(network, eval_results, iter, i)\n",
        "            actions.append(action)\n",
        "            reward = self.get_reward(action, label)\n",
        "\n",
        "            # only updates the model params in training mode\n",
        "            if is_training:\n",
        "                self.update(action, features, reward)\n",
        "\n",
        "            regret = self.get_reward(label, label) - reward\n",
        "            regrets.append(regret)\n",
        "            mistakes.append(0 if action == label else 1)\n",
        "            risks[label][action] += 1\n",
        "\n",
        "            if payoff is not None:\n",
        "                payoffs.append(payoff)\n",
        "            if conf_interval is not None:\n",
        "                conf_intervals.append(conf_interval)\n",
        "\n",
        "        return actions, regrets, mistakes, payoffs, conf_intervals, risks\n"
      ],
      "metadata": {
        "id": "iCR9gGSyoI3U"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lasso"
      ],
      "metadata": {
        "id": "5t1u4qu4Klef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from .recommender import Recommender\n",
        "# from .preprocess import *\n",
        "from sklearn.linear_model import Lasso\n",
        "from collections import defaultdict\n",
        "import logging\n",
        "class LassoBandit(Recommender):\n",
        "    \"\"\"\n",
        "    Implementation of Lasso bandit.\n",
        "\n",
        "    Reference: http://web.stanford.edu/~bayati/papers/lassoBandit.pdf\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            q: foced sampling parameter.\n",
        "            h: localization parameter.\n",
        "            lambda1: regularization parameter.\n",
        "            lambda2: regularization parameter.\n",
        "        \"\"\"\n",
        "        super().__init__(config)\n",
        "        self.num_arms = self.config.num_arms\n",
        "\n",
        "        # Forced sample hparam. Controls how frequently we force sample.\n",
        "        self.q = self.config.q\n",
        "        # Forced sample hparam. Controls how many force sample we generate. A very large\n",
        "        # number would generally suffice.\n",
        "        self.n = self.config.n\n",
        "\n",
        "        # Confidence param. We first use the force sample model to select a subset of arms\n",
        "        # based on this parameter. In practice we set this to a high number so that all arms\n",
        "        # are included because we only have 3 arms.\n",
        "        self.h = self.config.h\n",
        "        self.init_lambda1 = self.config.lambda1\n",
        "        self.init_lambda2 = self.config.lambda2\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        logging.debug(f\"[{self.config.algo_name}] reset!\")\n",
        "\n",
        "        # Keep tract of iteration time. This is used to schedule forced arm sampling.\n",
        "        self.t = 0\n",
        "\n",
        "        # Arm -> Lasso estimator trained on forced samples.\n",
        "        self.force_estimators = {}\n",
        "\n",
        "        # Arm -> Lasso estimator trained on all samples.\n",
        "        self.all_estimators = {}\n",
        "\n",
        "        # Arm -> iteration where we should force sample an arm.\n",
        "        self.force_sample_iter = defaultdict(set)\n",
        "\n",
        "        # Keeps track of past data\n",
        "        self.force_sample_X = defaultdict(list)\n",
        "        self.force_sample_y = defaultdict(list)\n",
        "        self.all_sample_X = defaultdict(list)\n",
        "        self.all_sample_y = defaultdict(list)\n",
        "\n",
        "        # Whether the previous prediction was forced.\n",
        "        self.forced = False\n",
        "\n",
        "        # Regularization.\n",
        "        self.lambda1 = self.init_lambda1\n",
        "        self.lambda2 = self.init_lambda2\n",
        "\n",
        "        # Initialize force sample schedule.\n",
        "        for a in range(self.num_arms):\n",
        "            K = self.num_arms\n",
        "            q = self.q\n",
        "            # In the paper the arm starts from 1.\n",
        "            i = a + 1\n",
        "            for j in range(q * (i - 1) + 1, q * i + 1):\n",
        "                for n in range(self.n):\n",
        "                    self.force_sample_iter[a].add((2 ** n - 1) * K * q + j)\n",
        "\n",
        "    def _train(self, lam, X, y):\n",
        "        lasso = Lasso(alpha=lam,)\n",
        "        lasso.fit(X, y)\n",
        "        return lasso\n",
        "\n",
        "    def get_features(self, network):\n",
        "        \"\"\"\n",
        "        Algorithm-specific feature processing\n",
        "\n",
        "        :param network: network data\n",
        "        :return: feature vector for the given network\n",
        "        \"\"\"\n",
        "        features = []\n",
        "        # features = list([1, network.properties[AGE].value])   # size 2\n",
        "        features.append(feature_scaling(0 , 42908 ,network.properties[DURATION]))\n",
        "        features.append(feature_scaling(0 ,1379963888,network.properties[SRC_BYTES]))\n",
        "        features.append(feature_scaling(0 ,1309937401,network.properties[DST_BYTES]))\n",
        "        features.append(feature_scaling(0 , 3,network.properties[WRONG_FRAGMENT]))\n",
        "        features.append(feature_scaling(0,3,network.properties[URGENT]))\n",
        "        features.append(feature_scaling(0 ,77,network.properties[HOT]))\n",
        "        features.append(feature_scaling(0 ,5,network.properties[NUM_FAILED_LOGINS]))\n",
        "        features.append(feature_scaling(0 , 7479 ,network.properties[NUM_COMPROMISED]))\n",
        "        features.append(feature_scaling(0 ,2,network.properties[SU_ATTEMPTED]))\n",
        "        features.append(feature_scaling(0 ,7468,network.properties[NUM_ROOT]))\n",
        "        features.append(feature_scaling(0 , 43,network.properties[NUM_FILE_CREATIONS]))\n",
        "        features.append(feature_scaling(0 ,3,network.properties[NUM_SHELLS]))\n",
        "        features.append(feature_scaling(0 ,9,network.properties[NUM_ACCESS_FILES]))\n",
        "        features.append(network.properties[NUM_OUTBOUND_CMDS])\n",
        "        features.append(feature_scaling(0 , 511 ,network.properties[COUNT]))\n",
        "        features.append(feature_scaling(0 ,511,network.properties[SRV_COUNT]))\n",
        "        features.append(network.properties[SERROR_RATE])\n",
        "        features.append(network.properties[SRV_SERROR_RATE])\n",
        "        features.append(network.properties[RERROR_RATE])\n",
        "        features.append(network.properties[SRV_RERROR_RATE])\n",
        "        features.append(network.properties[SAME_SRV_RATE])\n",
        "        features.append(network.properties[DIFF_SRV_RATE])\n",
        "        features.append(network.properties[SRV_DIFF_HOST_RATE])\n",
        "        features.append(feature_scaling(0 ,255,network.properties[DST_HOST_COUNT]))\n",
        "        features.append(feature_scaling(0 , 255,network.properties[DST_HOST_SRV_COUNT]))\n",
        "        features.append(network.properties[DST_HOST_SAME_SRV_RATE])\n",
        "        features.append(network.properties[DST_HOST_DIFF_SRV_RATE])\n",
        "        features.append(network.properties[DST_HOST_SAME_SRC_PORT_RATE])\n",
        "        features.append(network.properties[DST_HOST_SRV_DIFF_HOST_RATE])\n",
        "        features.append(network.properties[DST_HOST_SERROR_RATE])\n",
        "        features.append(network.properties[DST_HOST_SRV_SERROR_RATE])\n",
        "        features.append(network.properties[DST_HOST_RERROR_RATE])\n",
        "        features.append(network.properties[DST_HOST_SRV_RERROR_RATE])\n",
        "        features += get_one_hot(network.properties[PROTOCOL_TYPE])\n",
        "        features += get_one_hot(network.properties[SERVICE])\n",
        "        features +=get_one_hot(network.properties[FLAG])\n",
        "        for f in BINARY_FEATURES:\n",
        "            features += get_one_hot(network.properties[f]) # size: 5 * 3 = 69\n",
        "\n",
        "\n",
        "        return np.array(features)\n",
        "\n",
        "    def update(self, arm, context_feature, reward):\n",
        "        logging.debug(\n",
        "            f\"[{self.config.algo_name}] update: action={arm}; reward={reward}; context={context_feature}\")\n",
        "        if self.forced:\n",
        "            self.force_sample_X[arm].append(context_feature)\n",
        "            self.force_sample_y[arm].append(reward)\n",
        "            self.force_estimators[arm] = self._train(\n",
        "                self.lambda1,\n",
        "                self.force_sample_X[arm],\n",
        "                self.force_sample_y[arm]\n",
        "            )\n",
        "\n",
        "        self.all_sample_X[arm].append(context_feature)\n",
        "        self.all_sample_y[arm].append(reward)\n",
        "        self.lambda2 = self.init_lambda2 * np.sqrt(\n",
        "            (np.log(self.t) + np.log(len(context_feature))) / self.t)\n",
        "\n",
        "        self.all_estimators[arm] = self._train(\n",
        "                self.lambda2,\n",
        "                self.all_sample_X[arm],\n",
        "                self.all_sample_y[arm]\n",
        "            )\n",
        "\n",
        "    def _get_force_arm(self, t):\n",
        "        for a in range(self.num_arms):\n",
        "            if t in self.force_sample_iter[a]:\n",
        "                return a\n",
        "        return None\n",
        "\n",
        "    def _get_potential_arms(self, features):\n",
        "        potential_arms = []\n",
        "        predictions = []\n",
        "        for a in range(self.num_arms):\n",
        "            predictions.append(self.force_estimators[a].predict([features])[0])\n",
        "\n",
        "        max_pred = np.max(predictions)\n",
        "        for a, pred in enumerate(predictions):\n",
        "            if pred >= max_pred - self.h:\n",
        "                potential_arms.append(a)\n",
        "        return potential_arms\n",
        "\n",
        "    def _get_best_arm(self, potential_arms, features):\n",
        "        max_pred = -float(\"inf\")\n",
        "        best_arm = -1\n",
        "\n",
        "        for a in potential_arms:\n",
        "            pred = self.all_estimators[a].predict([features])[0]\n",
        "            if pred > max_pred:\n",
        "                max_pred = pred\n",
        "                best_arm = a\n",
        "        return best_arm\n",
        "\n",
        "    def recommend(self, network, eval_results, iter, network_idx):\n",
        "        self.t += 1\n",
        "\n",
        "        force_arm = self._get_force_arm(self.t)\n",
        "        if force_arm is not None:\n",
        "            self.forced = True\n",
        "            return force_arm, None, None\n",
        "\n",
        "        features = self.get_features(network)\n",
        "        potential_arms = self._get_potential_arms(features)\n",
        "        # print(\"potential arms:\", potential_arms)\n",
        "\n",
        "        self.forced = False\n",
        "        return self._get_best_arm(potential_arms, features), None, None\n"
      ],
      "metadata": {
        "id": "Bl8DCmPvo87Q"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LIN_UCB"
      ],
      "metadata": {
        "id": "2EUll00PKoxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import logging\n",
        "# from recommender import *\n",
        "# from feature import *\n",
        "# from constant import *\n",
        "# from preprocess import *\n",
        "\n",
        "\n",
        "class LinUCBDisjointRecommender(Recommender):\n",
        "    \"\"\"\n",
        "    Linear UCB with disjoint models.\n",
        "    Blog post: http://john-maxwell.com/post/2017-03-17/\n",
        "    Reference: Li, Lihong, Wei Chu, John Langford, and Robert E Schapire. 2010.\n",
        "    “A Contextual-Bandit Approach to Personalized News Article Recommendation.”\n",
        "    In Proceedings of the 19th International Conference on World Wide Web,\n",
        "    661–70. ACM.\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            alpha: regularization parameter.\n",
        "            d: number of features\n",
        "            num_arms: number of arms\n",
        "        \"\"\"\n",
        "        super().__init__(config)\n",
        "        self.alpha = self.config.alpha\n",
        "        self.d = self.config.feature_count\n",
        "        self.num_arms = len(self.config.actions)\n",
        "\n",
        "        # Convenience variable.\n",
        "        # A = D^T * D + I\n",
        "        # where D is the num_observation * d design matrix\n",
        "        # action -> d * d.\n",
        "        self.A = {}\n",
        "\n",
        "        # Learned params\n",
        "        # action -> d\n",
        "        self.theta = {}\n",
        "        self.b = {}\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        logging.debug(f\"[{self.config.algo_name}] reset!\")\n",
        "        for a in range(self.num_arms):\n",
        "            self.A[a] = np.identity(self.d)               # d x d\n",
        "            self.b[a] = np.atleast_2d(np.zeros(self.d)).T # d x 1\n",
        "\n",
        "    def get_features(self, network):\n",
        "        \"\"\"\n",
        "        Algorithm-specific feature processing\n",
        "\n",
        "        :param network: network data\n",
        "        :return: feature vector for the given network\n",
        "        \"\"\"\n",
        "        features = []\n",
        "        # features = list([1, network.properties[AGE].value])   # size 2\n",
        "        features.append(feature_scaling(0 , 42908 ,network.properties[DURATION]))\n",
        "        features.append(feature_scaling(0 ,1379963888,network.properties[SRC_BYTES]))\n",
        "        features.append(feature_scaling(0 ,1309937401,network.properties[DST_BYTES]))\n",
        "        features.append(feature_scaling(0 , 3,network.properties[WRONG_FRAGMENT]))\n",
        "        features.append(feature_scaling(0,3,network.properties[URGENT]))\n",
        "        features.append(feature_scaling(0 ,77,network.properties[HOT]))\n",
        "        features.append(feature_scaling(0 ,5,network.properties[NUM_FAILED_LOGINS]))\n",
        "        features.append(feature_scaling(0 , 7479 ,network.properties[NUM_COMPROMISED]))\n",
        "        features.append(feature_scaling(0 ,2,network.properties[SU_ATTEMPTED]))\n",
        "        features.append(feature_scaling(0 ,7468,network.properties[NUM_ROOT]))\n",
        "        features.append(feature_scaling(0 , 43,network.properties[NUM_FILE_CREATIONS]))\n",
        "        features.append(feature_scaling(0 ,3,network.properties[NUM_SHELLS]))\n",
        "        features.append(feature_scaling(0 ,9,network.properties[NUM_ACCESS_FILES]))\n",
        "        features.append(network.properties[NUM_OUTBOUND_CMDS])\n",
        "        features.append(feature_scaling(0 , 511 ,network.properties[COUNT]))\n",
        "        features.append(feature_scaling(0 ,511,network.properties[SRV_COUNT]))\n",
        "        features.append(network.properties[SERROR_RATE])\n",
        "        features.append(network.properties[SRV_SERROR_RATE])\n",
        "        features.append(network.properties[RERROR_RATE])\n",
        "        features.append(network.properties[SRV_RERROR_RATE])\n",
        "        features.append(network.properties[SAME_SRV_RATE])\n",
        "        features.append(network.properties[DIFF_SRV_RATE])\n",
        "        features.append(network.properties[SRV_DIFF_HOST_RATE])\n",
        "        features.append(feature_scaling(0 ,255,network.properties[DST_HOST_COUNT]))\n",
        "        features.append(feature_scaling(0 , 255,network.properties[DST_HOST_SRV_COUNT]))\n",
        "        features.append(network.properties[DST_HOST_SAME_SRV_RATE])\n",
        "        features.append(network.properties[DST_HOST_DIFF_SRV_RATE])\n",
        "        features.append(network.properties[DST_HOST_SAME_SRC_PORT_RATE])\n",
        "        features.append(network.properties[DST_HOST_SRV_DIFF_HOST_RATE])\n",
        "        features.append(network.properties[DST_HOST_SERROR_RATE])\n",
        "        features.append(network.properties[DST_HOST_SRV_SERROR_RATE])\n",
        "        features.append(network.properties[DST_HOST_RERROR_RATE])\n",
        "        features.append(network.properties[DST_HOST_SRV_RERROR_RATE])\n",
        "        features += get_one_hot(network.properties[PROTOCOL_TYPE])\n",
        "        features += get_one_hot(network.properties[SERVICE])\n",
        "        features +=get_one_hot(network.properties[FLAG])\n",
        "        for f in BINARY_FEATURES:\n",
        "            features += get_one_hot(network.properties[f]) # size: 5 * 3 = 69\n",
        "\n",
        "\n",
        "        return np.array(features)\n",
        "\n",
        "    def update(self, arm, context_feature, reward):\n",
        "        logging.debug(f\"[{self.config.algo_name}] update: action={arm}; reward={reward}; context={context_feature}\")\n",
        "        self.A[arm] += np.outer(context_feature, context_feature)\n",
        "        self.b[arm] += reward * np.reshape(context_feature, (self.d, 1))\n",
        "\n",
        "    def recommend(self, network, eval_results, iter, network_idx):\n",
        "        payoff = {}\n",
        "        best_arm = None\n",
        "        best_payoff = -float('inf')\n",
        "        best_conf_interval = None\n",
        "\n",
        "        fvec = self.get_features(network)\n",
        "        if fvec is None:\n",
        "            return None, None, None\n",
        "\n",
        "        for a in range(self.num_arms):\n",
        "            invA = np.linalg.inv(self.A[a])\n",
        "            self.theta[a] = np.dot(invA, self.b[a])\n",
        "            conf_interval = self.alpha * np.sqrt(np.dot(fvec.T, np.dot(invA, fvec)))\n",
        "\n",
        "            payoff[a] = (np.dot(self.theta[a].T, fvec)) + conf_interval\n",
        "\n",
        "            if payoff[a] > best_payoff:\n",
        "                best_payoff = payoff[a]\n",
        "                best_arm = a\n",
        "                best_conf_interval = conf_interval\n",
        "\n",
        "        logging.debug(f\"[{self.config.algo_name}] recommend: chosen action={best_arm}; \"\n",
        "                          f\"estimated payoff={best_payoff}; conf interval={best_conf_interval}\")\n",
        "\n",
        "        return best_arm, best_payoff, best_conf_interval\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZzvM_2MTKoWB"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CONFIG"
      ],
      "metadata": {
        "id": "8F-6P29NrQ_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from constant import *\n",
        "class ConfigCommon:\n",
        "    def __init__(self, output_path):\n",
        "        # output config\n",
        "        self.output_path = output_path\n",
        "        self.ensemble_list = [\"LinUCBDisjoint\", \"DTree-Alt\", \"Lasso\"]\n",
        "\n",
        "    def get_truth_filename(self, is_training):\n",
        "        s = \"training\" if is_training else \"testing\"\n",
        "        return f\"{self.output_path}{s}_truth.csv\"\n",
        "\n",
        "    def get_action_filename(self, model, is_training):\n",
        "        s = \"training\" if is_training else \"testing\"\n",
        "        return f\"{self.output_path}{s}_action_{model}.csv\"\n",
        "\n",
        "    def get_regret_filename(self, model, is_training):\n",
        "        s = \"training\" if is_training else \"testing\"\n",
        "        return f\"{self.output_path}{s}_regret_{model}.csv\"\n",
        "\n",
        "    def get_mistake_filename(self, model, is_training):\n",
        "        s = \"training\" if is_training else \"testing\"\n",
        "        return f\"{self.output_path}{s}_mistake_{model}.csv\"\n",
        "\n",
        "    def get_payoff_filename(self, model, is_training):\n",
        "        s = \"training\" if is_training else \"testing\"\n",
        "        return f\"{self.output_path}{s}_payoff_{model}.csv\"\n",
        "\n",
        "    def get_conf_interval_filename(self, model, is_training):\n",
        "        s = \"training\" if is_training else \"testing\"\n",
        "        return f\"{self.output_path}{s}_conf_interval_{model}.csv\"\n",
        "\n",
        "    def get_risk_filename(self, model, is_training):\n",
        "        s = \"training\" if is_training else \"testing\"\n",
        "        return f\"{self.output_path}{s}_risk_{model}.csv\"\n",
        "\n",
        "class ConfigLasso(ConfigCommon):\n",
        "\n",
        "    def __init__(self, output_path):\n",
        "        super().__init__(output_path)\n",
        "        self.algo_name = \"Lasso\"\n",
        "\n",
        "        self.num_arms = 2\n",
        "        # Essentially disable force sampling. We found it offers little\n",
        "        # benefit to the training.\n",
        "        self.q = 1\n",
        "        self.n = 10\n",
        "        self.h = 5\n",
        "        self.lambda1 = 0.05\n",
        "        self.lambda2 = 0.05\n",
        "\n",
        "class ConfigLinUCBDisjoint(ConfigCommon):\n",
        "\n",
        "    def __init__(self, output_path):\n",
        "        super().__init__(output_path)\n",
        "        self.algo_name = \"LinUCBDisjoint\"\n",
        "\n",
        "        # parameters for the model\n",
        "        self.actions = [0,1]\n",
        "        self.alpha = 0.01\n",
        "        self.feature_count = 135  # this must match actual feature count\n",
        "\n",
        "def get_config(algo_name, output_path):\n",
        "    if algo_name == \"lasso\":\n",
        "        return ConfigLasso(output_path)\n",
        "    elif algo_name == \"linucb_disjoint\":\n",
        "        return ConfigLinUCBDisjoint(output_path)\n"
      ],
      "metadata": {
        "id": "aKvvKEd6rQfF"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation"
      ],
      "metadata": {
        "id": "Z2cCEgGpYvUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility functions for evaluation.\n",
        "import numpy as np\n",
        "import logging\n",
        "import math\n",
        "# from config import *\n",
        "# from util import *\n",
        "import time\n",
        "\n",
        "class EvalResults:\n",
        "    \"\"\"\n",
        "    Class for encapsulating evaluation results\n",
        "    \"\"\"\n",
        "    def __init__(self, is_training, models, num_iter=1):\n",
        "        \"\"\"\n",
        "        Initialize EvalResults Class\n",
        "\n",
        "        \"\"\"\n",
        "        self.is_training = is_training\n",
        "        self.models = models\n",
        "        self.truths = [[]for i in range(num_iter)]\n",
        "        self.actions = [[[]for i in range(num_iter)] for j in range(len(models))]\n",
        "        self.regrets = [[[]for i in range(num_iter)] for j in range(len(models))]\n",
        "        self.mistakes = [[[] for i in range(num_iter)] for j in range(len(models))]\n",
        "        self.payoffs = [[[]for i in range(num_iter)] for j in range(len(models))]\n",
        "        self.conf_intervals = [[[]for i in range(num_iter)] for j in range(len(models))]\n",
        "        self.risks = [[[] for i in range(num_iter)] for j in range(len(models))]\n",
        "\n",
        "    def log_truths(self, iter_idx, networks, indices):\n",
        "        if len(self.truths[iter_idx]) == 0:\n",
        "            self.truths[iter_idx] = [networks[i].properties[CLASS] for i in indices]\n",
        "\n",
        "\n",
        "    def log_results(self, model_idx, iter_idx, actions, regrets, mistakes, payoffs, conf_intervals, risks):\n",
        "        self.actions[model_idx][iter_idx] = actions\n",
        "        self.regrets[model_idx][iter_idx] = regrets\n",
        "        self.mistakes[model_idx][iter_idx] = mistakes\n",
        "        self.payoffs[model_idx][iter_idx] = payoffs\n",
        "        self.conf_intervals[model_idx][iter_idx] = conf_intervals\n",
        "        self.risks[model_idx][iter_idx] = risks.flatten()\n",
        "\n",
        "    def export_results(self):\n",
        "        for m in range(len(self.models)):\n",
        "            model_config = self.models[m].config\n",
        "            if m == 0:\n",
        "                export_stats_list(self.truths,\n",
        "                                  model_config.get_truth_filename(self.is_training))\n",
        "            export_stats_list(self.actions[m],\n",
        "                              model_config.get_action_filename(model_config.algo_name, self.is_training))\n",
        "            export_stats_list(self.regrets[m],\n",
        "                              model_config.get_regret_filename(model_config.algo_name, self.is_training))\n",
        "            export_stats_list(self.mistakes[m],\n",
        "                              model_config.get_mistake_filename(model_config.algo_name, self.is_training))\n",
        "            if self.payoffs[m][0] is not None and len(self.payoffs[m][0]) > 0:\n",
        "                export_stats_list(self.payoffs[m],\n",
        "                                  model_config.get_payoff_filename(model_config.algo_name, self.is_training))\n",
        "            if self.conf_intervals[m][0] is not None and len(self.conf_intervals[m][0]) > 0:\n",
        "                export_stats_list(self.conf_intervals[m],\n",
        "                                  model_config.get_conf_interval_filename(model_config.algo_name, self.is_training))\n",
        "            export_stats_list(self.risks[m],\n",
        "                              model_config.get_risk_filename(model_config.algo_name, self.is_training))\n",
        "\n",
        "    def get_per_iter_mean_regret_for_model(self, model_idx, iter_idx):\n",
        "        \"\"\"\n",
        "        Returns mean regret for the given model across the given iteration\n",
        "\n",
        "        :param model_idx: index of the model\n",
        "        :param iter_idx: index of the iteration\n",
        "        :return: mean regret for the given model across the given iteration\n",
        "        \"\"\"\n",
        "        if self.regrets is None or model_idx < 0 or model_idx >= len(self.regrets) \\\n",
        "                or iter_idx < 0 or iter_idx >= len(self.regrets[0]):\n",
        "            return None\n",
        "\n",
        "        return np.mean(self.regrets[model_idx][iter_idx])\n",
        "\n",
        "    def get_overall_mean_regret_for_model(self, model_idx):\n",
        "        \"\"\"\n",
        "         Returns mean regret for the given model across all iterations\n",
        "\n",
        "         :param model_idx: index of the model\n",
        "         :return: mean regret for the given model across all iterations\n",
        "         \"\"\"\n",
        "        if self.regrets is None or model_idx < 0 or model_idx >= len(self.regrets):\n",
        "            return None\n",
        "\n",
        "        return np.mean([self.get_per_iter_mean_regret_for_model(model_idx, i)\n",
        "                        for i in range(len(self.regrets[model_idx]))])\n",
        "\n",
        "    def get_per_iter_total_regret_for_model(self, model_idx, iter_idx):\n",
        "        \"\"\"\n",
        "        Returns total regret for the given model across the given iteration\n",
        "\n",
        "        :param model_idx: index of the model\n",
        "        :param iter_idx: index of the iteration\n",
        "        :return: total regret for the given model across the given iteration\n",
        "        \"\"\"\n",
        "        if self.regrets is None or model_idx < 0 or model_idx >= len(self.regrets) \\\n",
        "                or iter_idx < 0 or iter_idx >= len(self.regrets[0]):\n",
        "            return None\n",
        "\n",
        "        return np.sum(self.regrets[model_idx][iter_idx])\n",
        "\n",
        "    def get_avg_total_regret_for_model(self, model_idx):\n",
        "        \"\"\"\n",
        "         Returns mean regret for the given model across all iterations\n",
        "\n",
        "         :param model_idx: index of the model\n",
        "         :return: mean regret for the given model across all iterations\n",
        "         \"\"\"\n",
        "        if self.regrets is None or model_idx < 0 or model_idx >= len(self.regrets):\n",
        "            return None\n",
        "\n",
        "        return np.mean([self.get_per_iter_total_regret_for_model(model_idx, i)\n",
        "                        for i in range(len(self.regrets[model_idx]))])\n",
        "\n",
        "    def get_per_iter_err_rate_for_model(self, model_idx, iter_idx):\n",
        "        \"\"\"\n",
        "        Returns error rate for the given model across the given iteration\n",
        "\n",
        "        :param model_idx: index of the model\n",
        "        :param iter_idx: index of the iteration\n",
        "        :return: error rate for the given model across the given iteration\n",
        "        \"\"\"\n",
        "        if self.mistakes is None or model_idx < 0 or model_idx >= len(self.mistakes) \\\n",
        "                or iter_idx < 0 or iter_idx >= len(self.mistakes[0]):\n",
        "            return None\n",
        "        return np.mean(self.mistakes[model_idx][iter_idx])\n",
        "\n",
        "    def get_overall_err_rate_for_model(self, model_idx):\n",
        "        \"\"\"\n",
        "        Returns error rate for the given model across all iterations\n",
        "        :param model_idx: index of the model\n",
        "        :return: error rate for the given model across all iterations\n",
        "        \"\"\"\n",
        "        if self.mistakes is None or model_idx < 0 or model_idx >= len(self.mistakes):\n",
        "            return None\n",
        "\n",
        "        return np.mean([self.get_per_iter_err_rate_for_model(model_idx, i)\n",
        "                        for i in range(len(self.mistakes[model_idx]))])\n",
        "\n",
        "\n",
        "def shuffle_split_data_set(networks, test_networks , trainset_ratio=0.8):\n",
        "    data_set_size = len(networks)\n",
        "    test_data_set_size = len(test_networks)\n",
        "\n",
        "    training_set_size = math.ceil(data_set_size * 1)\n",
        "    testing_set_size = math.ceil(test_data_set_size * 1)\n",
        "\n",
        "    indices = np.arange(data_set_size)\n",
        "    test_indices = np.arange(test_data_set_size)\n",
        "\n",
        "    np.random.shuffle(indices)\n",
        "    np.random.shuffle(test_indices)\n",
        "\n",
        "    training_indices = indices[:training_set_size]\n",
        "    testing_indices = test_indices[:testing_set_size]\n",
        "\n",
        "    # training_indices = test_indices[:testing_set_size]\n",
        "    # testing_indices = test_indices[testing_set_size:]\n",
        "    # testing_indices = test_indices[:testing_set_size]\n",
        "\n",
        "    print('trainin_indices ' , training_indices , len(training_indices))\n",
        "    print('testing_indices' , testing_indices) , len(testing_indices)\n",
        "    return training_indices, testing_indices\n",
        "\n",
        "\n",
        "# def run(networks, test_networks ,  models, num_iter=1, trainset_ratio=0.8, verbose=False):\n",
        "\n",
        "#     logging.info(f\"Starting model training/evaluation with: {len(networks)} networks, {num_iter} iterations,\"\n",
        "#                  f\"train_ratio={trainset_ratio}\")\n",
        "#     print(f\"Starting model training/evaluation with: {len(networks)} networks, {num_iter} iterations,\"\n",
        "#                  f\"train_ratio={trainset_ratio}\")\n",
        "#     np.random.seed(int(time.time()))\n",
        "\n",
        "#     if networks is None or len(networks) == 0 or test_networks is None or len(test_networks) == 0 or models is None or len(models) == 0 \\\n",
        "#             or num_iter < 1:\n",
        "#         return\n",
        "\n",
        "#     if trainset_ratio < 0: trainset_ratio = 0\n",
        "#     elif trainset_ratio > 1: trainset_ratio = 1\n",
        "\n",
        "#     # log all data for plotting\n",
        "#     training_results = EvalResults(True, models, num_iter) if trainset_ratio > 0 else None\n",
        "#     testing_results = EvalResults(False, models, num_iter) if trainset_ratio < 1 else None\n",
        "\n",
        "#     # perform N-fold validation based on the provided training/testing split\n",
        "#     # train the model on the training set then freeze the model to test on the testing set\n",
        "#     for i in range(num_iter):\n",
        "\n",
        "#         training_indices, testing_indices = shuffle_split_data_set(networks, test_networks ,  trainset_ratio)\n",
        "\n",
        "#         for m in range(len(models)):\n",
        "\n",
        "#             model = models[m]\n",
        "#             model.reset()\n",
        "\n",
        "#             # training on the training set\n",
        "#             if trainset_ratio > 0:\n",
        "#                 msg = f\"Training Iteration: {i}, model: {model.config.algo_name}\"\n",
        "#                 logging.info(msg)\n",
        "#                 if verbose:\n",
        "#                     print(msg)\n",
        "\n",
        "#                 # log ground truth for error analysis\n",
        "#                 training_results.log_truths(i, networks, training_indices)\n",
        "\n",
        "#                 training_actions, training_regrets, training_mistakes, training_payoffs, \\\n",
        "#                 training_conf_intervals, training_risks = \\\n",
        "#                     model.run(networks, training_indices, training_results, i, is_training=True)\n",
        "#                 # log training regret, estimated payoff & its confidence interval\n",
        "#                 training_results.log_results(m, i, training_actions, training_regrets, training_mistakes,\n",
        "#                                              training_payoffs, training_conf_intervals, training_risks)\n",
        "\n",
        "#                 msg = f\"total regret: {training_results.get_per_iter_total_regret_for_model(m, i)}, \" \\\n",
        "#                     f\"err rate: {training_results.get_per_iter_err_rate_for_model(m, i)}\"\n",
        "#                 logging.info(msg)\n",
        "#                 if verbose:\n",
        "#                     print(msg)\n",
        "\n",
        "#             # testing on the test set with the model params frozen\n",
        "#             if trainset_ratio <=1:\n",
        "#                 msg = f\"Testing Iteration: {i}, model: {model.config.algo_name}\"\n",
        "#                 logging.info(msg)\n",
        "#                 if verbose:\n",
        "#                     print(msg)\n",
        "\n",
        "#                 # log ground truth for error analysis\n",
        "#                 testing_results.log_truths(i, networks, testing_indices)\n",
        "\n",
        "#                 testing_actions, testing_regrest, testing_mistakes, testing_payoffs, \\\n",
        "#                 testing_conf_intervals, testing_risks = \\\n",
        "#                     model.run(networks, testing_indices, testing_results, i, is_training=False)\n",
        "#                 # log testing regret, estimated payoff & its confidence interval\n",
        "#                 testing_results.log_results(m, i, testing_actions, testing_regrest, testing_mistakes,\n",
        "#                                             testing_payoffs, testing_conf_intervals, testing_risks)\n",
        "\n",
        "#                 msg = f\"total regret: {testing_results.get_per_iter_total_regret_for_model(m, i)}, \" \\\n",
        "#                     f\"err rate: {testing_results.get_per_iter_err_rate_for_model(m, i)}\"\n",
        "#                 logging.info(msg)\n",
        "#                 if verbose:\n",
        "#                     print(msg)\n",
        "\n",
        "#     if trainset_ratio > 0:\n",
        "#         training_results.export_results()\n",
        "\n",
        "#     if trainset_ratio < 1:\n",
        "#         testing_results.export_results()\n",
        "\n",
        "#     # compose run summary message\n",
        "#     msg = f\"\\n------------------------\\n[SUMMARY OF THE RUN: {len(models)} model(s), {len(networks)} networks, \" \\\n",
        "#         f\"{num_iter} iteration(s)]\\n\"\n",
        "#     train_percentage = trainset_ratio * 100\n",
        "#     if trainset_ratio > 0:\n",
        "#         msg += f\"------------------------\\nTraining: {len(training_indices)} ({train_percentage}%) networks\\n\"\n",
        "#         for m in range(len(models)):\n",
        "#             msg += f\"[{models[m].config.algo_name}] \" \\\n",
        "#                 f\"total regret: {training_results.get_avg_total_regret_for_model(m)}, \" \\\n",
        "#                 f\"err rate: {training_results.get_overall_err_rate_for_model(m)}\\n\"\n",
        "\n",
        "#     if trainset_ratio < 1:\n",
        "#         msg += f\"------------------------\\nTesting: {len(testing_indices)} ({100 - train_percentage }%) networks\\n\"\n",
        "#         for m in range(len(models)):\n",
        "#             msg += f\"[{models[m].config.algo_name}] \" \\\n",
        "#                 f\"total regret: {testing_results.get_avg_total_regret_for_model(m)}, \" \\\n",
        "#                 f\"err rate: {testing_results.get_overall_err_rate_for_model(m)}\\n\"\n",
        "\n",
        "#     logging.info(msg)\n",
        "#     if verbose:\n",
        "#         print(msg)\n",
        "\n",
        "def run(networks, test_networks ,  models, num_iter=1, trainset_ratio=0.8, verbose=False):\n",
        "\n",
        "    logging.info(f\"Starting model training/evaluation with: {len(networks)} networks, {num_iter} iterations,\"\n",
        "                 f\"train_ratio={trainset_ratio}\")\n",
        "    print(f\"Starting model training/evaluation with: {len(networks)} networks, {num_iter} iterations,\"\n",
        "                 f\"train_ratio={trainset_ratio}\")\n",
        "    np.random.seed(int(time.time()))\n",
        "\n",
        "    if networks is None or len(networks) == 0 or test_networks is None or len(test_networks) == 0 or models is None or len(models) == 0 \\\n",
        "            or num_iter < 1:\n",
        "        return\n",
        "\n",
        "    if trainset_ratio < 0: trainset_ratio = 0\n",
        "    elif trainset_ratio > 1: trainset_ratio = 1\n",
        "\n",
        "    # log all data for plotting\n",
        "    training_results = EvalResults(True, models, num_iter) if trainset_ratio > 0 else None\n",
        "    testing_results = EvalResults(False, models, num_iter) if trainset_ratio < 1 else None\n",
        "\n",
        "    # perform N-fold validation based on the provided training/testing split\n",
        "    # train the model on the training set then freeze the model to test on the testing set\n",
        "    for i in range(num_iter):\n",
        "\n",
        "        training_indices, testing_indices = shuffle_split_data_set(networks, test_networks ,  trainset_ratio)\n",
        "\n",
        "        for m in range(len(models)):\n",
        "\n",
        "            model = models[m]\n",
        "            model.reset()\n",
        "\n",
        "            # training on the training set\n",
        "            if trainset_ratio > 0:\n",
        "                msg = f\"Training Iteration: {i}, model: {model.config.algo_name}\"\n",
        "                logging.info(msg)\n",
        "                if verbose:\n",
        "                    print(msg)\n",
        "\n",
        "                # log ground truth for error analysis\n",
        "                training_results.log_truths(i, networks, training_indices)\n",
        "\n",
        "                training_actions, training_regrets, training_mistakes, training_payoffs, \\\n",
        "                training_conf_intervals, training_risks = \\\n",
        "                    model.run(networks, training_indices, training_results, i, is_training=True)\n",
        "                # log training regret, estimated payoff & its confidence interval\n",
        "                training_results.log_results(m, i, training_actions, training_regrets, training_mistakes,\n",
        "                                             training_payoffs, training_conf_intervals, training_risks)\n",
        "\n",
        "                msg = f\"total regret: {training_results.get_per_iter_total_regret_for_model(m, i)}, \" \\\n",
        "                    f\"err rate: {training_results.get_per_iter_err_rate_for_model(m, i)}\"\n",
        "                logging.info(msg)\n",
        "                if verbose:\n",
        "                    print(msg)\n",
        "\n",
        "            # testing on the test set with the model params frozen\n",
        "            if trainset_ratio <=1:\n",
        "                msg = f\"Testing Iteration: {i}, model: {model.config.algo_name}\"\n",
        "                logging.info(msg)\n",
        "                if verbose:\n",
        "                    print(msg)\n",
        "\n",
        "                # log ground truth for error analysis\n",
        "                testing_results.log_truths(i, test_networks, testing_indices)\n",
        "\n",
        "                testing_actions, testing_regrest, testing_mistakes, testing_payoffs, \\\n",
        "                testing_conf_intervals, testing_risks = \\\n",
        "                    model.run(test_networks, testing_indices, testing_results, i, is_training=False)\n",
        "                # log testing regret, estimated payoff & its confidence interval\n",
        "                testing_results.log_results(m, i, testing_actions, testing_regrest, testing_mistakes,\n",
        "                                            testing_payoffs, testing_conf_intervals, testing_risks)\n",
        "\n",
        "                msg = f\"total regret: {testing_results.get_per_iter_total_regret_for_model(m, i)}, \" \\\n",
        "                    f\"err rate: {testing_results.get_per_iter_err_rate_for_model(m, i)}\"\n",
        "                logging.info(msg)\n",
        "                if verbose:\n",
        "                    print(msg)\n",
        "\n",
        "    if trainset_ratio > 0:\n",
        "        training_results.export_results()\n",
        "\n",
        "    if trainset_ratio < 1:\n",
        "        testing_results.export_results()\n",
        "\n",
        "    # compose run summary message\n",
        "    msg = f\"\\n------------------------\\n[SUMMARY OF THE RUN: {len(models)} model(s), {len(networks)} networks, \" \\\n",
        "        f\"{num_iter} iteration(s)]\\n\"\n",
        "    # train_percentage = trainset_ratio * 100\n",
        "    train_percentage = 100\n",
        "    if trainset_ratio > 0:\n",
        "        msg += f\"------------------------\\nTraining: {len(training_indices)} ({train_percentage}%) networks\\n\"\n",
        "        for m in range(len(models)):\n",
        "            msg += f\"[{models[m].config.algo_name}] \" \\\n",
        "                f\"total regret: {training_results.get_avg_total_regret_for_model(m)}, \" \\\n",
        "                f\"err rate: {training_results.get_overall_err_rate_for_model(m)}\\n\"\n",
        "\n",
        "    if trainset_ratio < 1:\n",
        "        msg += f\"------------------------\\nTesting: {len(testing_indices)} ({100}%) networks\\n\"\n",
        "        for m in range(len(models)):\n",
        "            msg += f\"[{models[m].config.algo_name}] \" \\\n",
        "                f\"total regret: {testing_results.get_avg_total_regret_for_model(m)}, \" \\\n",
        "                f\"err rate: {testing_results.get_overall_err_rate_for_model(m)}\\n\"\n",
        "\n",
        "    logging.info(msg)\n",
        "    if verbose:\n",
        "        print(msg)\n"
      ],
      "metadata": {
        "id": "8s8a6idhrXVX"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MAIN"
      ],
      "metadata": {
        "id": "Q05-5oWnrvWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "import argparse\n",
        "import logging\n",
        "from itertools import islice\n",
        "# from .eva\n",
        "# from lasso_bandit import LassoBandit\n",
        "# from network import Network\n",
        "import datetime\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--algo\", required=True , type=str)\n",
        "parser.add_argument(\"--iter\", required=False, type=int)\n",
        "parser.add_argument(\"--train_ratio\", required=False, type=float)\n",
        "\n",
        "\n",
        "def get_recommender(algo, output_path):\n",
        "\n",
        "    # default recommender: FixedDose\n",
        "    # model = FixedDoseRecommender(get_config(algo, output_path))\n",
        "\n",
        "    if algo == \"lasso\":\n",
        "        model = LassoBandit(get_config(algo, output_path))\n",
        "    elif  algo == \"linucb_disjoint\":\n",
        "        model = LinUCBDisjointRecommender(get_config(algo, output_path))\n",
        "\n",
        "\n",
        "    # elif algo == \"linucb_disjoint\":\n",
        "    #     model = LinUCBDisjointRecommender(get_config(algo, output_path))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def parse_all_test_records(records , keep_missing = False):\n",
        "  results = list()\n",
        "  raw_test_count = 0\n",
        "  # records = islice(records , 1000)\n",
        "  for r in records:\n",
        "    raw_test_count +=1\n",
        "    network = Network(r)\n",
        "    results.append(network)\n",
        "  logging.info(f\"Parsing raw  test records: loaded test record count={raw_test_count}, returned network count={len(results)}, \"\n",
        "                f\"keep_missing={keep_missing}\")\n",
        "  print('test' , len(results))\n",
        "  return results\n",
        "\n",
        "def  load_test_data(filename):\n",
        "  logging.info(f\"Loading test data set from : {filename}\")\n",
        "  raw_test_data = csv.DictReader(open(filename))\n",
        "  return parse_all_test_records(raw_test_data , keep_missing = False)\n",
        "\n",
        "\n",
        "def parse_all_records(records, keep_missing=False):\n",
        "    \"\"\"\n",
        "    Parse data rows loaded from csv into list of Network\n",
        "\n",
        "    :param records: DictReader of the csv\n",
        "    :return: list of Network\n",
        "    \"\"\"\n",
        "    results = list()\n",
        "    rawCount = 0\n",
        "    # print(records)\n",
        "    # records = islice(records,1)\n",
        "    for r in records:\n",
        "        # print('r')\n",
        "        rawCount += 1\n",
        "        network = Network(r)\n",
        "        results.append(network)\n",
        "    logging.info(f\"Parsing raw records: loaded record count={rawCount}, returned network count={len(results)}, \"\n",
        "                 f\"keep_missing={keep_missing}\")\n",
        "    print('train',len(results) )\n",
        "    return results\n",
        "\n",
        "\n",
        "def load_data(filename):\n",
        "    logging.info(f\"Loading data set from: {filename}\")\n",
        "    raw_data = csv.DictReader(open(filename))\n",
        "    return parse_all_records(raw_data, keep_missing=False)\n",
        "\n",
        "output_path = \"results/{}/\".format(datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
        "# directory for outputs\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "log_path = output_path + \"log.txt\"\n",
        "logging.basicConfig(filename=log_path, format='%(asctime)s:%(levelname)s: %(message)s', level=logging.INFO)\n",
        "\n",
        "datafile = \"KDDTrain+.csv\"\n",
        "testdatafile = \"KDDTest+.csv\"\n",
        "networks = load_data(datafile)\n",
        "test_networks = load_test_data(testdatafile)\n",
        "\n",
        "# algo = 'lasso'\n",
        "algo = \"linucb_disjoint\"\n",
        "# print(networks[3].properties)\n",
        "models = []\n",
        "logging.info(f\"Initializing recommender model(s): {algo}\")\n",
        "models += [get_recommender(algo, output_path)]\n",
        "\n",
        "iters =1\n",
        "train_ratio = 0.8\n",
        "\n",
        "run(networks, test_networks , models, iters, train_ratio, verbose=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulCVTgyyrwgD",
        "outputId": "fc643962-8517-4d09-a901-e89a850c6e11"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 125973\n",
            "test 22544\n",
            "Starting model training/evaluation with: 125973 networks, 1 iterations,train_ratio=0.8\n",
            "trainin_indices  [ 88757  50847 110799 ...  70776 114060 118015] 125973\n",
            "testing_indices [  964    32  7122 ...   520  5966 21753]\n",
            "Training Iteration: 0, model: LinUCBDisjoint\n",
            "total regret: 7212, err rate: 0.028625181586530445\n",
            "Testing Iteration: 0, model: LinUCBDisjoint\n",
            "total regret: 10660, err rate: 0.2364265436479773\n",
            "\n",
            "------------------------\n",
            "[SUMMARY OF THE RUN: 1 model(s), 125973 networks, 1 iteration(s)]\n",
            "------------------------\n",
            "Training: 125973 (100%) networks\n",
            "[LinUCBDisjoint] total regret: 7212.0, err rate: 0.028625181586530445\n",
            "------------------------\n",
            "Testing: 22544 (100%) networks\n",
            "[LinUCBDisjoint] total regret: 10660.0, err rate: 0.2364265436479773\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#lasso run"
      ],
      "metadata": {
        "id": "VAIBsG2QZ10m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "import argparse\n",
        "import logging\n",
        "from itertools import islice\n",
        "# from .eva\n",
        "# from lasso_bandit import LassoBandit\n",
        "# from network import Network\n",
        "import datetime\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--algo\", required=True , type=str)\n",
        "parser.add_argument(\"--iter\", required=False, type=int)\n",
        "parser.add_argument(\"--train_ratio\", required=False, type=float)\n",
        "\n",
        "\n",
        "def get_recommender(algo, output_path):\n",
        "\n",
        "    # default recommender: FixedDose\n",
        "    # model = FixedDoseRecommender(get_config(algo, output_path))\n",
        "\n",
        "    if algo == \"lasso\":\n",
        "        model = LassoBandit(get_config(algo, output_path))\n",
        "    elif  algo == \"linucb_disjoint\":\n",
        "        model = LinUCBDisjointRecommender(get_config(algo, output_path))\n",
        "\n",
        "\n",
        "    # elif algo == \"linucb_disjoint\":\n",
        "    #     model = LinUCBDisjointRecommender(get_config(algo, output_path))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def parse_all_test_records(records , keep_missing = False):\n",
        "  results = list()\n",
        "  raw_test_count = 0\n",
        "  records = islice(records , 4000)\n",
        "  for r in records:\n",
        "    raw_test_count +=1\n",
        "    network = Network(r)\n",
        "    results.append(network)\n",
        "  logging.info(f\"Parsing raw  test records: loaded test record count={raw_test_count}, returned network count={len(results)}, \"\n",
        "                f\"keep_missing={keep_missing}\")\n",
        "  print('test' , len(results))\n",
        "  return results\n",
        "\n",
        "def  load_test_data(filename):\n",
        "  logging.info(f\"Loading test data set from : {filename}\")\n",
        "  raw_test_data = csv.DictReader(open(filename))\n",
        "  return parse_all_test_records(raw_test_data , keep_missing = False)\n",
        "\n",
        "\n",
        "def parse_all_records(records, keep_missing=False):\n",
        "    \"\"\"\n",
        "    Parse data rows loaded from csv into list of Network\n",
        "\n",
        "    :param records: DictReader of the csv\n",
        "    :return: list of Network\n",
        "    \"\"\"\n",
        "    results = list()\n",
        "    rawCount = 0\n",
        "    # print(records)\n",
        "    records = islice(records,20000)\n",
        "    for r in records:\n",
        "        # print('r')\n",
        "        rawCount += 1\n",
        "        network = Network(r)\n",
        "        results.append(network)\n",
        "    logging.info(f\"Parsing raw records: loaded record count={rawCount}, returned network count={len(results)}, \"\n",
        "                 f\"keep_missing={keep_missing}\")\n",
        "    print('train',len(results) )\n",
        "    return results\n",
        "\n",
        "\n",
        "def load_data(filename):\n",
        "    logging.info(f\"Loading data set from: {filename}\")\n",
        "    raw_data = csv.DictReader(open(filename))\n",
        "    return parse_all_records(raw_data, keep_missing=False)\n",
        "\n",
        "output_path = \"results/{}/\".format(datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
        "# directory for outputs\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "log_path = output_path + \"log.txt\"\n",
        "logging.basicConfig(filename=log_path, format='%(asctime)s:%(levelname)s: %(message)s', level=logging.INFO)\n",
        "\n",
        "datafile = \"KDDTrain+.csv\"\n",
        "testdatafile = \"KDDTest+.csv\"\n",
        "networks = load_data(datafile)\n",
        "test_networks = load_test_data(testdatafile)\n",
        "\n",
        "algo = 'lasso'\n",
        "# algo = \"linucb_disjoint\"\n",
        "# print(networks[3].properties)\n",
        "models = []\n",
        "logging.info(f\"Initializing recommender model(s): {algo}\")\n",
        "models += [get_recommender(algo, output_path)]\n",
        "\n",
        "iters =1\n",
        "train_ratio = 0.8\n",
        "\n",
        "run(networks, test_networks , models, iters, train_ratio, verbose=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIAcCJJPZ3rM",
        "outputId": "1783f9ac-39ba-4e73-c1fc-48748bf430be"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 20000\n",
            "test 4000\n",
            "Starting model training/evaluation with: 20000 networks, 1 iterations,train_ratio=0.8\n",
            "trainin_indices  [ 7333 18247 11898 ... 12800  4020  9118] 20000\n",
            "testing_indices [2842 1964 1138 ... 1346 2205 3733]\n",
            "Training Iteration: 0, model: Lasso\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.156e-03, tolerance: 8.889e-04\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total regret: 1276, err rate: 0.0319\n",
            "Testing Iteration: 0, model: Lasso\n",
            "total regret: 1948, err rate: 0.2435\n",
            "\n",
            "------------------------\n",
            "[SUMMARY OF THE RUN: 1 model(s), 20000 networks, 1 iteration(s)]\n",
            "------------------------\n",
            "Training: 20000 (100%) networks\n",
            "[Lasso] total regret: 1276.0, err rate: 0.0319\n",
            "------------------------\n",
            "Testing: 4000 (100%) networks\n",
            "[Lasso] total regret: 1948.0, err rate: 0.2435\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_features(network):\n",
        "  \"\"\"\n",
        "  Algorithm-specific feature processing\n",
        "\n",
        "  :param network: network data\n",
        "  :return: feature vector for the given network\n",
        "  \"\"\"\n",
        "  features = []\n",
        "  # features = list([1, network.properties[AGE].value])   # size 2\n",
        "  features.append(feature_scaling(0 , 42908 ,network.properties[DURATION]))\n",
        "  features.append(feature_scaling(0 ,1379963888,network.properties[SRC_BYTES]))\n",
        "  features.append(feature_scaling(0 ,1309937401,network.properties[DST_BYTES]))\n",
        "  features.append(feature_scaling(0 , 3,network.properties[WRONG_FRAGMENT]))\n",
        "  features.append(feature_scaling(0,3,network.properties[URGENT]))\n",
        "  features.append(feature_scaling(0 ,77,network.properties[HOT]))\n",
        "  features.append(feature_scaling(0 ,5,network.properties[NUM_FAILED_LOGINS]))\n",
        "  features.append(feature_scaling(0 , 7479 ,network.properties[NUM_COMPROMISED]))\n",
        "  features.append(feature_scaling(0 ,2,network.properties[SU_ATTEMPTED]))\n",
        "  features.append(feature_scaling(0 ,7468,network.properties[NUM_ROOT]))\n",
        "  features.append(feature_scaling(0 , 43,network.properties[NUM_FILE_CREATIONS]))\n",
        "  features.append(feature_scaling(0 ,3,network.properties[NUM_SHELLS]))\n",
        "  features.append(feature_scaling(0 ,9,network.properties[NUM_ACCESS_FILES]))\n",
        "  features.append(network.properties[NUM_OUTBOUND_CMDS])\n",
        "  features.append(feature_scaling(0 , 511 ,network.properties[COUNT]))\n",
        "  features.append(feature_scaling(0 ,511,network.properties[SRV_COUNT]))\n",
        "  features.append(network.properties[SERROR_RATE])\n",
        "  features.append(network.properties[SRV_SERROR_RATE])\n",
        "  features.append(network.properties[RERROR_RATE])\n",
        "  features.append(network.properties[SRV_RERROR_RATE])\n",
        "  features.append(network.properties[SAME_SRV_RATE])\n",
        "  features.append(network.properties[DIFF_SRV_RATE])\n",
        "  features.append(network.properties[SRV_DIFF_HOST_RATE])\n",
        "  features.append(feature_scaling(0 ,255,network.properties[DST_HOST_COUNT]))\n",
        "  features.append(feature_scaling(0 , 255,network.properties[DST_HOST_SRV_COUNT]))\n",
        "  features.append(network.properties[DST_HOST_SAME_SRV_RATE])\n",
        "  features.append(network.properties[DST_HOST_DIFF_SRV_RATE])\n",
        "  features.append(network.properties[DST_HOST_SAME_SRC_PORT_RATE])\n",
        "  features.append(network.properties[DST_HOST_SRV_DIFF_HOST_RATE])\n",
        "  features.append(network.properties[DST_HOST_SERROR_RATE])\n",
        "  features.append(network.properties[DST_HOST_SRV_SERROR_RATE])\n",
        "  features.append(network.properties[DST_HOST_RERROR_RATE])\n",
        "  features.append(network.properties[DST_HOST_SRV_RERROR_RATE])\n",
        "  features += get_one_hot(network.properties[PROTOCOL_TYPE])\n",
        "  features += get_one_hot(network.properties[SERVICE])\n",
        "  features +=get_one_hot(network.properties[FLAG])\n",
        "  # print(features)\n",
        "  for f in BINARY_FEATURES:\n",
        "      features += get_one_hot(network.properties[f]) # size: 23 * 3 = 69\n",
        "  print(features)\n",
        "get_features(networks[1])\n",
        "print(len([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.4481409001956947, 0.019569471624266144, 0.0, 0.0, 1.0, 1.0, 0.04, 0.06, 0.0, 1.0, 0.0392156862745098, 0.04, 0.06, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSkHJ751zlKz",
        "outputId": "45896307-e8fc-4a12-d238-ef8233b57527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, 1.0579987003254102e-07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.025440313111545987, 0.0019569471624266144, 0.0, 0.0, 0.0, 0.0, 0.08, 0.15, 0.0, 1.0, 0.00392156862745098, 0.0, 0.6, 0.88, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1]\n",
            "135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pd.set_option('display.max_columns', None)\n",
        "# df.head()"
      ],
      "metadata": {
        "id": "sGgkCFLeyARw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test Dataset"
      ],
      "metadata": {
        "id": "VKb7Igd3Y-aE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Upload the CSV file to Google Colab\n",
        "# After uploading the file, it will be available in the current working directory.\n",
        "\n",
        "# Step 2: Import the required libraries and read the CSV file into a DataFrame\n",
        "file_path = 'KDDTest+.csv'  # Replace 'your_file_name.csv' with the actual file name\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Step 3: View the summary of the DataFrame\n",
        "# Using .info() to get information about the DataFrame\n",
        "print(\"Data Summary:\")\n",
        "print(df.info())\n",
        "\n",
        "# Using .describe() to get basic statistics of numerical columns\n",
        "print(\"\\nBasic Statistics:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Additionally, you can use .head() to see the first few rows of the DataFrame\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "cNyArMX9tnYM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e3f569d-3672-49ef-af9f-9e9f9dbeaddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Summary:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 22544 entries, 0 to 22543\n",
            "Data columns (total 42 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   duration                     22544 non-null  int64  \n",
            " 1   protocol_type                22544 non-null  object \n",
            " 2   service                      22544 non-null  object \n",
            " 3   flag                         22544 non-null  object \n",
            " 4   src_bytes                    22544 non-null  int64  \n",
            " 5   dst_bytes                    22544 non-null  int64  \n",
            " 6   land                         22544 non-null  int64  \n",
            " 7   wrong_fragment               22544 non-null  int64  \n",
            " 8   urgent                       22544 non-null  int64  \n",
            " 9   hot                          22544 non-null  int64  \n",
            " 10  num_failed_logins            22544 non-null  int64  \n",
            " 11  logged_in                    22544 non-null  int64  \n",
            " 12  num_compromised              22544 non-null  int64  \n",
            " 13  root_shell                   22544 non-null  int64  \n",
            " 14  su_attempted                 22544 non-null  int64  \n",
            " 15  num_root                     22544 non-null  int64  \n",
            " 16  num_file_creations           22544 non-null  int64  \n",
            " 17  num_shells                   22544 non-null  int64  \n",
            " 18  num_access_files             22544 non-null  int64  \n",
            " 19  num_outbound_cmds            22544 non-null  int64  \n",
            " 20  is_host_login                22544 non-null  int64  \n",
            " 21  is_guest_login               22544 non-null  int64  \n",
            " 22  count                        22544 non-null  int64  \n",
            " 23  srv_count                    22544 non-null  int64  \n",
            " 24  serror_rate                  22544 non-null  float64\n",
            " 25  srv_serror_rate              22544 non-null  float64\n",
            " 26  rerror_rate                  22544 non-null  float64\n",
            " 27  srv_rerror_rate              22544 non-null  float64\n",
            " 28  same_srv_rate                22544 non-null  float64\n",
            " 29  diff_srv_rate                22544 non-null  float64\n",
            " 30  srv_diff_host_rate           22544 non-null  float64\n",
            " 31  dst_host_count               22544 non-null  int64  \n",
            " 32  dst_host_srv_count           22544 non-null  int64  \n",
            " 33  dst_host_same_srv_rate       22544 non-null  float64\n",
            " 34  dst_host_diff_srv_rate       22544 non-null  float64\n",
            " 35  dst_host_same_src_port_rate  22544 non-null  float64\n",
            " 36  dst_host_srv_diff_host_rate  22544 non-null  float64\n",
            " 37  dst_host_serror_rate         22544 non-null  float64\n",
            " 38  dst_host_srv_serror_rate     22544 non-null  float64\n",
            " 39  dst_host_rerror_rate         22544 non-null  float64\n",
            " 40  dst_host_srv_rerror_rate     22544 non-null  float64\n",
            " 41  class                        22544 non-null  object \n",
            "dtypes: float64(15), int64(23), object(4)\n",
            "memory usage: 7.2+ MB\n",
            "None\n",
            "\n",
            "Basic Statistics:\n",
            "           duration     src_bytes     dst_bytes          land  wrong_fragment  \\\n",
            "count  22544.000000  2.254400e+04  2.254400e+04  22544.000000    22544.000000   \n",
            "mean     218.859076  1.039545e+04  2.056019e+03      0.000311        0.008428   \n",
            "std     1407.176612  4.727864e+05  2.121930e+04      0.017619        0.142599   \n",
            "min        0.000000  0.000000e+00  0.000000e+00      0.000000        0.000000   \n",
            "25%        0.000000  0.000000e+00  0.000000e+00      0.000000        0.000000   \n",
            "50%        0.000000  5.400000e+01  4.600000e+01      0.000000        0.000000   \n",
            "75%        0.000000  2.870000e+02  6.010000e+02      0.000000        0.000000   \n",
            "max    57715.000000  6.282565e+07  1.345927e+06      1.000000        3.000000   \n",
            "\n",
            "             urgent           hot  num_failed_logins     logged_in  \\\n",
            "count  22544.000000  22544.000000       22544.000000  22544.000000   \n",
            "mean       0.000710      0.105394           0.021647      0.442202   \n",
            "std        0.036473      0.928428           0.150328      0.496659   \n",
            "min        0.000000      0.000000           0.000000      0.000000   \n",
            "25%        0.000000      0.000000           0.000000      0.000000   \n",
            "50%        0.000000      0.000000           0.000000      0.000000   \n",
            "75%        0.000000      0.000000           0.000000      1.000000   \n",
            "max        3.000000    101.000000           4.000000      1.000000   \n",
            "\n",
            "       num_compromised  ...  dst_host_count  dst_host_srv_count  \\\n",
            "count     22544.000000  ...    22544.000000        22544.000000   \n",
            "mean          0.119899  ...      193.869411          140.750532   \n",
            "std           7.269597  ...       94.035663          111.783972   \n",
            "min           0.000000  ...        0.000000            0.000000   \n",
            "25%           0.000000  ...      121.000000           15.000000   \n",
            "50%           0.000000  ...      255.000000          168.000000   \n",
            "75%           0.000000  ...      255.000000          255.000000   \n",
            "max         796.000000  ...      255.000000          255.000000   \n",
            "\n",
            "       dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
            "count            22544.000000            22544.000000   \n",
            "mean                 0.608722                0.090540   \n",
            "std                  0.435688                0.220717   \n",
            "min                  0.000000                0.000000   \n",
            "25%                  0.070000                0.000000   \n",
            "50%                  0.920000                0.010000   \n",
            "75%                  1.000000                0.060000   \n",
            "max                  1.000000                1.000000   \n",
            "\n",
            "       dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
            "count                 22544.000000                 22544.000000   \n",
            "mean                      0.132261                     0.019638   \n",
            "std                       0.306268                     0.085394   \n",
            "min                       0.000000                     0.000000   \n",
            "25%                       0.000000                     0.000000   \n",
            "50%                       0.000000                     0.000000   \n",
            "75%                       0.030000                     0.010000   \n",
            "max                       1.000000                     1.000000   \n",
            "\n",
            "       dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
            "count          22544.000000              22544.000000          22544.000000   \n",
            "mean               0.097814                  0.099426              0.233385   \n",
            "std                0.273139                  0.281866              0.387229   \n",
            "min                0.000000                  0.000000              0.000000   \n",
            "25%                0.000000                  0.000000              0.000000   \n",
            "50%                0.000000                  0.000000              0.000000   \n",
            "75%                0.000000                  0.000000              0.360000   \n",
            "max                1.000000                  1.000000              1.000000   \n",
            "\n",
            "       dst_host_srv_rerror_rate  \n",
            "count              22544.000000  \n",
            "mean                   0.226683  \n",
            "std                    0.400875  \n",
            "min                    0.000000  \n",
            "25%                    0.000000  \n",
            "50%                    0.000000  \n",
            "75%                    0.170000  \n",
            "max                    1.000000  \n",
            "\n",
            "[8 rows x 38 columns]\n",
            "\n",
            "First few rows:\n",
            "   duration protocol_type   service  flag  src_bytes  dst_bytes  land  \\\n",
            "0         0           tcp   private   REJ          0          0     0   \n",
            "1         0           tcp   private   REJ          0          0     0   \n",
            "2         2           tcp  ftp_data    SF      12983          0     0   \n",
            "3         0          icmp     eco_i    SF         20          0     0   \n",
            "4         1           tcp    telnet  RSTO          0         15     0   \n",
            "\n",
            "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
            "0               0       0    0  ...                  10   \n",
            "1               0       0    0  ...                   1   \n",
            "2               0       0    0  ...                  86   \n",
            "3               0       0    0  ...                  57   \n",
            "4               0       0    0  ...                  86   \n",
            "\n",
            "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
            "0                    0.04                    0.06   \n",
            "1                    0.00                    0.06   \n",
            "2                    0.61                    0.04   \n",
            "3                    1.00                    0.00   \n",
            "4                    0.31                    0.17   \n",
            "\n",
            "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
            "0                         0.00                         0.00   \n",
            "1                         0.00                         0.00   \n",
            "2                         0.61                         0.02   \n",
            "3                         1.00                         0.28   \n",
            "4                         0.03                         0.02   \n",
            "\n",
            "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
            "0                   0.0                       0.0                  1.00   \n",
            "1                   0.0                       0.0                  1.00   \n",
            "2                   0.0                       0.0                  0.00   \n",
            "3                   0.0                       0.0                  0.00   \n",
            "4                   0.0                       0.0                  0.83   \n",
            "\n",
            "   dst_host_srv_rerror_rate    class  \n",
            "0                      1.00  anomaly  \n",
            "1                      1.00  anomaly  \n",
            "2                      0.00   normal  \n",
            "3                      0.00  anomaly  \n",
            "4                      0.71  anomaly  \n",
            "\n",
            "[5 rows x 42 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train Dataset"
      ],
      "metadata": {
        "id": "GL6fpfKWZWea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Upload the CSV file to Google Colab\n",
        "# After uploading the file, it will be available in the current working directory.\n",
        "# Step 2: Import the required libraries and read the CSV file into a DataFrame\n",
        "file_path = 'KDDTrain+.csv'  # Replace 'your_file_name.csv' with the actual file name\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Step 3: View the summary of the DataFrame\n",
        "# Using .info() to get information about the DataFrame\n",
        "print(\"Data Summary:\")\n",
        "print(df.info())\n",
        "\n",
        "# Using .describe() to get basic statistics of numerical columns\n",
        "print(\"\\nBasic Statistics:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Additionally, you can use .head() to see the first few rows of the DataFrame\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWyZtEhExNEn",
        "outputId": "57734eae-a803-490f-8eee-95a6983ba5d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Summary:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 125973 entries, 0 to 125972\n",
            "Data columns (total 42 columns):\n",
            " #   Column                       Non-Null Count   Dtype  \n",
            "---  ------                       --------------   -----  \n",
            " 0   duration                     125973 non-null  int64  \n",
            " 1   protocol_type                125973 non-null  object \n",
            " 2   service                      125973 non-null  object \n",
            " 3   flag                         125973 non-null  object \n",
            " 4   src_bytes                    125973 non-null  int64  \n",
            " 5   dst_bytes                    125973 non-null  int64  \n",
            " 6   land                         125973 non-null  int64  \n",
            " 7   wrong_fragment               125973 non-null  int64  \n",
            " 8   urgent                       125973 non-null  int64  \n",
            " 9   hot                          125973 non-null  int64  \n",
            " 10  num_failed_logins            125973 non-null  int64  \n",
            " 11  logged_in                    125973 non-null  int64  \n",
            " 12  num_compromised              125973 non-null  int64  \n",
            " 13  root_shell                   125973 non-null  int64  \n",
            " 14  su_attempted                 125973 non-null  int64  \n",
            " 15  num_root                     125973 non-null  int64  \n",
            " 16  num_file_creations           125973 non-null  int64  \n",
            " 17  num_shells                   125973 non-null  int64  \n",
            " 18  num_access_files             125973 non-null  int64  \n",
            " 19  num_outbound_cmds            125973 non-null  int64  \n",
            " 20  is_host_login                125973 non-null  int64  \n",
            " 21  is_guest_login               125973 non-null  int64  \n",
            " 22  count                        125973 non-null  int64  \n",
            " 23  srv_count                    125973 non-null  int64  \n",
            " 24  serror_rate                  125973 non-null  float64\n",
            " 25  srv_serror_rate              125973 non-null  float64\n",
            " 26  rerror_rate                  125973 non-null  float64\n",
            " 27  srv_rerror_rate              125973 non-null  float64\n",
            " 28  same_srv_rate                125973 non-null  float64\n",
            " 29  diff_srv_rate                125973 non-null  float64\n",
            " 30  srv_diff_host_rate           125973 non-null  float64\n",
            " 31  dst_host_count               125973 non-null  int64  \n",
            " 32  dst_host_srv_count           125973 non-null  int64  \n",
            " 33  dst_host_same_srv_rate       125973 non-null  float64\n",
            " 34  dst_host_diff_srv_rate       125973 non-null  float64\n",
            " 35  dst_host_same_src_port_rate  125973 non-null  float64\n",
            " 36  dst_host_srv_diff_host_rate  125973 non-null  float64\n",
            " 37  dst_host_serror_rate         125973 non-null  float64\n",
            " 38  dst_host_srv_serror_rate     125973 non-null  float64\n",
            " 39  dst_host_rerror_rate         125973 non-null  float64\n",
            " 40  dst_host_srv_rerror_rate     125973 non-null  float64\n",
            " 41  class                        125973 non-null  object \n",
            "dtypes: float64(15), int64(23), object(4)\n",
            "memory usage: 40.4+ MB\n",
            "None\n",
            "\n",
            "Basic Statistics:\n",
            "           duration     src_bytes     dst_bytes           land  \\\n",
            "count  125973.00000  1.259730e+05  1.259730e+05  125973.000000   \n",
            "mean      287.14465  4.556674e+04  1.977911e+04       0.000198   \n",
            "std      2604.51531  5.870331e+06  4.021269e+06       0.014086   \n",
            "min         0.00000  0.000000e+00  0.000000e+00       0.000000   \n",
            "25%         0.00000  0.000000e+00  0.000000e+00       0.000000   \n",
            "50%         0.00000  4.400000e+01  0.000000e+00       0.000000   \n",
            "75%         0.00000  2.760000e+02  5.160000e+02       0.000000   \n",
            "max     42908.00000  1.379964e+09  1.309937e+09       1.000000   \n",
            "\n",
            "       wrong_fragment         urgent            hot  num_failed_logins  \\\n",
            "count   125973.000000  125973.000000  125973.000000      125973.000000   \n",
            "mean         0.022687       0.000111       0.204409           0.001222   \n",
            "std          0.253530       0.014366       2.149968           0.045239   \n",
            "min          0.000000       0.000000       0.000000           0.000000   \n",
            "25%          0.000000       0.000000       0.000000           0.000000   \n",
            "50%          0.000000       0.000000       0.000000           0.000000   \n",
            "75%          0.000000       0.000000       0.000000           0.000000   \n",
            "max          3.000000       3.000000      77.000000           5.000000   \n",
            "\n",
            "           logged_in  num_compromised  ...  dst_host_count  \\\n",
            "count  125973.000000    125973.000000  ...   125973.000000   \n",
            "mean        0.395736         0.279250  ...      182.148945   \n",
            "std         0.489010        23.942042  ...       99.206213   \n",
            "min         0.000000         0.000000  ...        0.000000   \n",
            "25%         0.000000         0.000000  ...       82.000000   \n",
            "50%         0.000000         0.000000  ...      255.000000   \n",
            "75%         1.000000         0.000000  ...      255.000000   \n",
            "max         1.000000      7479.000000  ...      255.000000   \n",
            "\n",
            "       dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
            "count       125973.000000           125973.000000           125973.000000   \n",
            "mean           115.653005                0.521242                0.082951   \n",
            "std            110.702741                0.448949                0.188922   \n",
            "min              0.000000                0.000000                0.000000   \n",
            "25%             10.000000                0.050000                0.000000   \n",
            "50%             63.000000                0.510000                0.020000   \n",
            "75%            255.000000                1.000000                0.070000   \n",
            "max            255.000000                1.000000                1.000000   \n",
            "\n",
            "       dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
            "count                125973.000000                125973.000000   \n",
            "mean                      0.148379                     0.032542   \n",
            "std                       0.308997                     0.112564   \n",
            "min                       0.000000                     0.000000   \n",
            "25%                       0.000000                     0.000000   \n",
            "50%                       0.000000                     0.000000   \n",
            "75%                       0.060000                     0.020000   \n",
            "max                       1.000000                     1.000000   \n",
            "\n",
            "       dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
            "count         125973.000000             125973.000000         125973.000000   \n",
            "mean               0.284452                  0.278485              0.118832   \n",
            "std                0.444784                  0.445669              0.306557   \n",
            "min                0.000000                  0.000000              0.000000   \n",
            "25%                0.000000                  0.000000              0.000000   \n",
            "50%                0.000000                  0.000000              0.000000   \n",
            "75%                1.000000                  1.000000              0.000000   \n",
            "max                1.000000                  1.000000              1.000000   \n",
            "\n",
            "       dst_host_srv_rerror_rate  \n",
            "count             125973.000000  \n",
            "mean                   0.120240  \n",
            "std                    0.319459  \n",
            "min                    0.000000  \n",
            "25%                    0.000000  \n",
            "50%                    0.000000  \n",
            "75%                    0.000000  \n",
            "max                    1.000000  \n",
            "\n",
            "[8 rows x 38 columns]\n",
            "\n",
            "First few rows:\n",
            "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
            "0         0           tcp  ftp_data   SF        491          0     0   \n",
            "1         0           udp     other   SF        146          0     0   \n",
            "2         0           tcp   private   S0          0          0     0   \n",
            "3         0           tcp      http   SF        232       8153     0   \n",
            "4         0           tcp      http   SF        199        420     0   \n",
            "\n",
            "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
            "0               0       0    0  ...                  25   \n",
            "1               0       0    0  ...                   1   \n",
            "2               0       0    0  ...                  26   \n",
            "3               0       0    0  ...                 255   \n",
            "4               0       0    0  ...                 255   \n",
            "\n",
            "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
            "0                    0.17                    0.03   \n",
            "1                    0.00                    0.60   \n",
            "2                    0.10                    0.05   \n",
            "3                    1.00                    0.00   \n",
            "4                    1.00                    0.00   \n",
            "\n",
            "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
            "0                         0.17                         0.00   \n",
            "1                         0.88                         0.00   \n",
            "2                         0.00                         0.00   \n",
            "3                         0.03                         0.04   \n",
            "4                         0.00                         0.00   \n",
            "\n",
            "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
            "0                  0.00                      0.00                  0.05   \n",
            "1                  0.00                      0.00                  0.00   \n",
            "2                  1.00                      1.00                  0.00   \n",
            "3                  0.03                      0.01                  0.00   \n",
            "4                  0.00                      0.00                  0.00   \n",
            "\n",
            "   dst_host_srv_rerror_rate    class  \n",
            "0                      0.00   normal  \n",
            "1                      0.00   normal  \n",
            "2                      0.00  anomaly  \n",
            "3                      0.01   normal  \n",
            "4                      0.00   normal  \n",
            "\n",
            "[5 rows x 42 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len([0.0, 1.6812034142157205e-07, 6.2239615372276864e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.009784735812133072, 0.009784735812133072, 0.2, 0.2, 0.0, 0.0, 1.0, 0.0, 0.0, 0.11764705882352941, 1.0, 1.0, 0.0, 0.03, 0.04, 0.03, 0.01, 0.0, 0.01, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeTsdYtaLxky",
        "outputId": "99f9729c-0c07-435a-96db-a6cf4a384bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Upload the CSV file to Google Colab\n",
        "# After uploading the file, it will be available in the current working directory.\n",
        "\n",
        "# Step 2: Import the required libraries and read the CSV file into a DataFrame\n",
        "file_path = 'KDDTrain+.csv'  # Replace 'your_file_name.csv' with the actual file name\n",
        "df1 = pd.read_csv(file_path)\n",
        "df1.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "JWX3q2Bt1ZMl",
        "outputId": "3fca554a-9897-46a8-e092-6a6409f73a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
              "0         0           tcp  ftp_data   SF        491          0     0   \n",
              "1         0           udp     other   SF        146          0     0   \n",
              "2         0           tcp   private   S0          0          0     0   \n",
              "3         0           tcp      http   SF        232       8153     0   \n",
              "4         0           tcp      http   SF        199        420     0   \n",
              "\n",
              "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
              "0               0       0    0  ...                  25   \n",
              "1               0       0    0  ...                   1   \n",
              "2               0       0    0  ...                  26   \n",
              "3               0       0    0  ...                 255   \n",
              "4               0       0    0  ...                 255   \n",
              "\n",
              "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
              "0                    0.17                    0.03   \n",
              "1                    0.00                    0.60   \n",
              "2                    0.10                    0.05   \n",
              "3                    1.00                    0.00   \n",
              "4                    1.00                    0.00   \n",
              "\n",
              "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
              "0                         0.17                         0.00   \n",
              "1                         0.88                         0.00   \n",
              "2                         0.00                         0.00   \n",
              "3                         0.03                         0.04   \n",
              "4                         0.00                         0.00   \n",
              "\n",
              "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
              "0                  0.00                      0.00                  0.05   \n",
              "1                  0.00                      0.00                  0.00   \n",
              "2                  1.00                      1.00                  0.00   \n",
              "3                  0.03                      0.01                  0.00   \n",
              "4                  0.00                      0.00                  0.00   \n",
              "\n",
              "   dst_host_srv_rerror_rate    class  \n",
              "0                      0.00   normal  \n",
              "1                      0.00   normal  \n",
              "2                      0.00  anomaly  \n",
              "3                      0.01   normal  \n",
              "4                      0.00   normal  \n",
              "\n",
              "[5 rows x 42 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-0f21f191-55f6-4775-877e-8d2874309ab9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>duration</th>\n",
              "      <th>protocol_type</th>\n",
              "      <th>service</th>\n",
              "      <th>flag</th>\n",
              "      <th>src_bytes</th>\n",
              "      <th>dst_bytes</th>\n",
              "      <th>land</th>\n",
              "      <th>wrong_fragment</th>\n",
              "      <th>urgent</th>\n",
              "      <th>hot</th>\n",
              "      <th>...</th>\n",
              "      <th>dst_host_srv_count</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_diff_srv_rate</th>\n",
              "      <th>dst_host_same_src_port_rate</th>\n",
              "      <th>dst_host_srv_diff_host_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>dst_host_rerror_rate</th>\n",
              "      <th>dst_host_srv_rerror_rate</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>ftp_data</td>\n",
              "      <td>SF</td>\n",
              "      <td>491</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>25</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>udp</td>\n",
              "      <td>other</td>\n",
              "      <td>SF</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>private</td>\n",
              "      <td>S0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>26</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>anomaly</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>SF</td>\n",
              "      <td>232</td>\n",
              "      <td>8153</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>255</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>SF</td>\n",
              "      <td>199</td>\n",
              "      <td>420</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>255</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 42 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f21f191-55f6-4775-877e-8d2874309ab9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-b8c3e623-cc79-4844-bf93-f5f1fd00df06\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b8c3e623-cc79-4844-bf93-f5f1fd00df06')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-b8c3e623-cc79-4844-bf93-f5f1fd00df06 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0f21f191-55f6-4775-877e-8d2874309ab9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0f21f191-55f6-4775-877e-8d2874309ab9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}